03-29 05:14:33 I ------------------
03-29 05:14:33 I initializing wandb (mode=online)
03-29 05:14:35 I logged into wandb (host=https://api.wandb.ai/)
03-29 05:14:40 I ------------------
03-29 05:14:40 I python main_train.py --devices 0,1,2,3,4,5,6,7 --hp yamls_paper/probe/run/h14/2fwil9ec.yaml
03-29 05:14:40 I ------------------
03-29 05:14:40 I VERSION CHECK
03-29 05:14:40 I python version: 3.9.15
03-29 05:14:40 I torch version: 1.13.0.post200
03-29 05:14:40 I torchmetrics version: 0.11.0
03-29 05:14:40 I kappabenchmark version: 0.0.10
03-29 05:14:40 I kappaconfig version: 1.0.29
03-29 05:14:40 I kappadata version: 1.0.99
03-29 05:14:40 I kappaprofiler version: 1.0.9
03-29 05:14:40 I kappaschedules version: 0.0.7
03-29 05:14:40 I pytorch_concurrent_dataloader version: 0.0.7
03-29 05:14:40 I torchmetrics version: 0.11.0
03-29 05:14:40 I ------------------
03-29 05:14:40 I SYSTEM INFO
03-29 05:14:40 I total_cpu_count: 128
03-29 05:14:40 I ------------------
03-29 05:14:40 I CLI ARGS
03-29 05:14:40 I hp: yamls_paper/probe/run/h14/2fwil9ec.yaml
03-29 05:14:40 I accelerator: gpu
03-29 05:14:40 I devices: 0,1,2,3,4,5,6,7
03-29 05:14:40 I testrun: False
03-29 05:14:40 I minmodelrun: False
03-29 05:14:40 I mindatarun: False
03-29 05:14:40 I mindurationrun: False
03-29 05:14:40 I datasets_were_preloaded: False
03-29 05:14:40 I disable_flash_attention: False
03-29 05:14:40 I ------------------
03-29 05:14:40 I DIST CONFIG
03-29 05:14:40 I rank: 0
03-29 05:14:40 I local_rank: 0
03-29 05:14:40 I world_size: 8
03-29 05:14:40 I nodes: 1
03-29 05:14:40 I backend: nccl
03-29 05:14:40 I pbs job id: 1807161.infra-pbs
03-29 05:14:40 I ------------------
stage_name: probe
datasets:
  train:
    kind: image_net
    version: imagenet1k
    split: train
    x_transform:
    - kind: kd_random_resized_crop
      size: 224
      scale:
      - 0.08
      - 1.0
      interpolation: bicubic
    - kind: random_horizontal_flip
    - kind: kd_image_net_norm
  test:
    kind: image_net
    version: imagenet1k
    split: test
    x_transform:
    - kind: kd_resize
      size: 256
      interpolation: bicubic
    - kind: center_crop
      size: 224
    - kind: kd_image_net_norm
model:
  kind: backbone_head
  backbone:
    is_frozen: true
    initializer:
      kind: previous_run_initializer
      stage_id: 2fwil9ec
      stage_name: stage2
      model_name: mae_contheads_vit.encoder
      model_info: ema=0.9999
      checkpoint: last
      use_checkpoint_kwargs: true
  head:
    kind: heads.multi_linear_head
    poolings:
      cls:
        kind: class_token
    initializers:
      default:
        kind: trunc_normal_initializer
        std: 0.01
    optimizers:
      sgd_lr01_wupcos_wd0:
        kind: sgd
        lr: 0.1
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr009_wupcos_wd0:
        kind: sgd
        lr: 0.09
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr008_wupcos_wd0:
        kind: sgd
        lr: 0.08
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr007_wupcos_wd0:
        kind: sgd
        lr: 0.07
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr006_wupcos_wd0:
        kind: sgd
        lr: 0.06
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr005_wupcos_wd0:
        kind: sgd
        lr: 0.05
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr004_wupcos_wd0:
        kind: sgd
        lr: 0.04
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr003_wupcos_wd0:
        kind: sgd
        lr: 0.03
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr002_wupcos_wd0:
        kind: sgd
        lr: 0.02
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
      sgd_lr001_wupcos_wd0:
        kind: sgd
        lr: 0.01
        momentum: 0.9
        schedule:
        - kind: linear
          end_percent: 10.0
        - kind: cosine_annealing
trainer:
  kind: classification_trainer
  effective_batch_size: 1024
  max_epochs: 50
  log_every_n_epochs: 1
  precision: bfloat16
  loggers:
  - kind: accuracy_logger
    every_n_epochs: 1
    dataset_key: test
  - kind: checkpoint_logger
    save_optim: false
    save_latest_optim: false
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr01_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr01_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr009_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr009_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr008_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr008_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr007_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr007_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr006_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr006_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr005_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr005_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr004_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr004_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr003_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr003_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr002_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr002_wupcos_wd0_default
  - kind: best_model_logger
    every_n_epochs: 1
    metric_key: accuracy1/test/cls_sgd_lr001_wupcos_wd0_default
    model_name: backbone_head.head.cls_sgd_lr001_wupcos_wd0_default
summary_summarizers:
- kind: best_metric_summary_summarizer
  pattern: accuracy1/test*/last
- kind: best_metric_summary_summarizer
  pattern: accuracy1/test*/max
- kind: best_metric_summary_summarizer
  pattern: accuracy1/test/cls_*/last
- kind: best_metric_summary_summarizer
  pattern: accuracy1/test/cls_*/max
03-29 05:14:40 I copied unresolved hp to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/hp_unresolved.yaml
03-29 05:14:40 I dumped resolved hp to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/hp_resolved.yaml
03-29 05:14:40 I ------------------
03-29 05:14:40 I training stage 'probe'
03-29 05:14:40 I no seed specified -> using seed=5
03-29 05:14:40 I using different seeds per process (seed+rank) 
03-29 05:14:40 I set seed to 5
03-29 05:14:40 I ------------------
03-29 05:14:40 I initializing datasets
03-29 05:14:40 I initialzing train
03-29 05:14:40 I data_source (global): '/scratch/project/dd-22-71/data/imagenet1k/train'
03-29 05:14:40 I data_source (local): '/tmp/imagenet1k/train'
03-29 05:14:40 I extracting 1000 zips from '/scratch/project/dd-22-71/data/imagenet1k/train' to '/tmp/imagenet1k/train' using 1 workers
03-29 05:21:51 I finished copying data from global to local
03-29 05:21:51 I source_root '/tmp/imagenet1k/train' contains 1000 folders
03-29 05:21:56 I initialzing test
03-29 05:21:56 I data_source (global): '/scratch/project/dd-22-71/data/imagenet1k/val'
03-29 05:21:56 I data_source (local): '/tmp/imagenet1k/val'
03-29 05:21:56 I extracting 1000 zips from '/scratch/project/dd-22-71/data/imagenet1k/val' to '/tmp/imagenet1k/val' using 1 workers
03-29 05:22:19 I finished copying data from global to local
03-29 05:22:19 I source_root '/tmp/imagenet1k/val' contains 1000 folders
03-29 05:22:19 I ------------------
03-29 05:22:19 I initializing trainer
03-29 05:22:19 I ------------------
03-29 05:22:19 I creating model
03-29 05:22:20 I using fixed positional embedding
03-29 05:22:20 I using FlashAttention
03-29 05:22:31 I loaded weights of mae_contheads_vit.encoder from /home/it4i-johleh/scratch/save_mlp/stage2/2fwil9ec/checkpoints/mae_contheads_vit.encoder cp=last ema=0.9999 model.th
03-29 05:22:31 I copying config and summary
03-29 05:22:32 I masked_encoder skipping model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I initialized LinearHead with weight=trunc_normal(std=0.01) bias=0
03-29 05:22:32 I linear_head applying model specific initialization
03-29 05:22:32 I applying model specific initialization
03-29 05:22:32 I skipping model specific initialization
03-29 05:22:32 I masked_encoder is frozen -> no optimizer to initialize
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 1e-1
03-29 05:22:32 I scaled lr: 0.4 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 9e-2
03-29 05:22:32 I scaled lr: 0.36 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 8e-2
03-29 05:22:32 I scaled lr: 0.32 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 7e-2
03-29 05:22:32 I scaled lr: 0.28 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 6e-2
03-29 05:22:32 I scaled lr: 0.24 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 5e-2
03-29 05:22:32 I scaled lr: 0.2 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 4e-2
03-29 05:22:32 I scaled lr: 0.16 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 3e-2
03-29 05:22:32 I scaled lr: 0.12 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 2e-2
03-29 05:22:32 I scaled lr: 0.08 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I linear_head initialize optimizer
03-29 05:22:32 I unscaled lr: 1e-2
03-29 05:22:32 I scaled lr: 0.04 (LinearLrScaler(divisor=256) lr_scaler_factor=1024)
03-29 05:22:32 I group modifiers exclude_bias_from_wd=True exclude_norm_from_wd=True []
03-29 05:22:32 I added default EtaLogger(every_n_epochs=1)
03-29 05:22:32 I added default DatasetStatsLogger()
03-29 05:22:32 I added default ParamCountLogger()
03-29 05:22:32 I added default ProgressLogger(every_n_epochs=1)
03-29 05:22:32 I added default TrainTimeLogger(every_n_epochs=1)
03-29 05:22:32 I added default OnlineLossLogger(every_n_epochs=1)
03-29 05:22:32 I added default LrLogger(every_n_updates=50)
03-29 05:22:32 I added default FreezerLogger(every_n_updates=50)
03-29 05:22:32 I added default OnlineLossLogger(every_n_updates=50)
03-29 05:22:32 I ------------------
03-29 05:22:32 I PREPARE TRAINER
03-29 05:22:32 I calculating batch_size and accumulation_steps (effective_batch_size=1024)
03-29 05:22:32 I model is batch_size dependent -> disabled possible gradient accumulation
03-29 05:22:32 I train_batches per epoch: 1251 (world_size=8 batch_size=128)
03-29 05:22:32 I initializing train dataloader
03-29 05:22:32 I created 'train' dataloader (type=pytorch batch_size=128 num_workers=11 pin_memory=True dataset_length=1281167 persistent_workers=True total_cpu_count=128)
03-29 05:22:32 I ------------------
03-29 05:22:32 I BEFORE TRAINING
03-29 05:22:32 I train: 1281167 samples
03-29 05:22:32 I skipping dataset statistics for train (too big len(ds)=1281167)
03-29 05:22:32 I test: 50000 samples
03-29 05:22:32 I test has 1000 classes (1000 classes with samples)
03-29 05:22:32 I each class has at least 50 samples
03-29 05:22:32 I each class has at most 50 samples
03-29 05:22:32 I each class has on average 50.0 samples
03-29 05:22:32 I parameter counts (trainable | frozen)
03-29 05:22:32 I 12,810,000 |  630,435,840 | total
03-29 05:22:32 I          0 |  630,435,840 | backbone.masked_encoder
03-29 05:22:32 I 12,810,000 |            0 | head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr01_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr009_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr008_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr007_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr006_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr005_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr004_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr003_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr002_wupcos_wd0_default.linear_head
03-29 05:22:32 I  1,281,000 |            0 | head.cls_sgd_lr001_wupcos_wd0_default.linear_head
03-29 05:22:33 I created 'test' dataloader (type=pytorch batch_size=128 num_workers=4 pin_memory=True dataset_length=50000 persistent_workers=True total_cpu_count=128)
03-29 05:22:33 I estimated checkpoint size: 7.7GB
03-29 05:22:33 I estimated weight checkpoint size: 2.5GB
03-29 05:22:33 I estimated optim checkpoint size: 5.1GB
03-29 05:22:33 I estimated size for 1 checkpoints: 2.5GB
03-29 05:22:33 I ------------------
03-29 05:22:33 I EtaLogger(every_n_epochs=1)
03-29 05:22:33 I DatasetStatsLogger()
03-29 05:22:33 I ParamCountLogger()
03-29 05:22:33 I ProgressLogger(every_n_epochs=1)
03-29 05:22:33 I TrainTimeLogger(every_n_epochs=1)
03-29 05:22:33 I OnlineLossLogger(every_n_epochs=1)
03-29 05:22:33 I LrLogger(every_n_updates=50)
03-29 05:22:33 I FreezerLogger(every_n_updates=50)
03-29 05:22:33 I OnlineLossLogger(every_n_updates=50)
03-29 05:22:33 I AccuracyLogger(every_n_epochs=1)
03-29 05:22:33 I CheckpointLogger()
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I BestModelLogger(every_n_epochs=1)
03-29 05:22:33 I ------------------
03-29 05:22:33 I START TRAINING
03-29 05:22:33 I initializing dataloader workers
03-29 05:23:09 I initialized dataloader workers
03-29 05:23:20 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 05:23:22 I 0 unused parameters
03-29 05:23:22 I Reducer buckets have been rebuilt in this iteration.
03-29 05:31:16 I ------------------
03-29 05:31:16 I Epoch 1 (E1_U1251_S1281024)
03-29 05:31:16 I train_iter=[36.84, 36.71, 35.29, 37.07, 36.43, 35.93, 35.28, 37.35] train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 05:31:16 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.87208474
03-29 05:31:16 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.91742266
03-29 05:31:16 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.97062349
03-29 05:31:16 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 2.03275215
03-29 05:31:16 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 2.11073520
03-29 05:31:16 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 2.21198628
03-29 05:31:16 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 2.34402381
03-29 05:31:16 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 2.53560571
03-29 05:31:16 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 2.85584389
03-29 05:31:16 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 3.52509454
03-29 05:31:16 I loss/online/total: 23.37617246
03-29 05:31:33 I accuracy_logger_test_iter=9.81 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 05:31:36 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7814
03-29 05:31:36 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7812
03-29 05:31:36 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7819
03-29 05:31:36 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7808
03-29 05:31:36 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7802
03-29 05:31:36 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7775
03-29 05:31:36 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7749
03-29 05:31:36 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7709
03-29 05:31:36 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.7610
03-29 05:31:36 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.7423
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): -inf --> 0.7813599705696106
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): -inf --> 0.7811599969863892
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): -inf --> 0.7818999886512756
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): -inf --> 0.7808200120925903
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): -inf --> 0.7802000045776367
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): -inf --> 0.7775200009346008
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): -inf --> 0.7749199867248535
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): -inf --> 0.7709000110626221
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): -inf --> 0.7609999775886536
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 05:31:36 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): -inf --> 0.7422800064086914
03-29 05:31:36 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 05:31:36 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 05:31:36 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 05:39:29 I ------------------
03-29 05:39:29 I Epoch 2 (E2_U2502_S2562048)
03-29 05:39:29 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 05:39:29 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.99122359
03-29 05:39:29 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.98795118
03-29 05:39:29 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.98577176
03-29 05:39:29 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.98538152
03-29 05:39:29 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.98771820
03-29 05:39:29 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.99370913
03-29 05:39:29 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 1.00442421
03-29 05:39:29 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 1.02413821
03-29 05:39:29 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 1.06254398
03-29 05:39:29 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 1.16330963
03-29 05:39:29 I loss/online/total: 10.18617140
03-29 05:39:47 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 05:39:49 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7827
03-29 05:39:49 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7846
03-29 05:39:49 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7857
03-29 05:39:50 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7867
03-29 05:39:50 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7874
03-29 05:39:50 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7889
03-29 05:39:50 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7889
03-29 05:39:50 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7885
03-29 05:39:50 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.7865
03-29 05:39:50 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.7764
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7813599705696106 --> 0.7827200293540955
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7811599969863892 --> 0.7845799922943115
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7818999886512756 --> 0.7856799960136414
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7808200120925903 --> 0.7867199778556824
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7802000045776367 --> 0.7874000072479248
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7775200009346008 --> 0.788860023021698
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7749199867248535 --> 0.788860023021698
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7709000110626221 --> 0.7885199785232544
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.7609999775886536 --> 0.7864800095558167
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 05:39:50 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.7422800064086914 --> 0.7764000296592712
03-29 05:39:50 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 05:39:50 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 05:39:50 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 05:47:43 I ------------------
03-29 05:47:43 I Epoch 3 (E3_U3753_S3843072)
03-29 05:47:43 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 05:47:43 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.00294357
03-29 05:47:43 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.98696408
03-29 05:47:43 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.97251297
03-29 05:47:43 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.96005645
03-29 05:47:43 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.95035397
03-29 05:47:43 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.94384433
03-29 05:47:43 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.94145341
03-29 05:47:43 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.94587214
03-29 05:47:43 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.96262275
03-29 05:47:43 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 1.01408448
03-29 05:47:43 I loss/online/total: 9.68070814
03-29 05:48:01 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 05:48:03 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7766
03-29 05:48:03 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7797
03-29 05:48:03 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7822
03-29 05:48:03 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7851
03-29 05:48:03 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7884
03-29 05:48:03 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7911
03-29 05:48:03 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7935
03-29 05:48:03 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7944
03-29 05:48:03 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.7936
03-29 05:48:03 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.7882
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7874000072479248 --> 0.7883800268173218
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.788860023021698 --> 0.7910799980163574
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.788860023021698 --> 0.7935400009155273
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7885199785232544 --> 0.7944200038909912
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.7864800095558167 --> 0.7936000227928162
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 05:48:03 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.7764000296592712 --> 0.7882000207901001
03-29 05:48:03 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 05:48:03 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 05:48:03 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 05:55:56 I ------------------
03-29 05:55:56 I Epoch 4 (E4_U5004_S5124096)
03-29 05:55:56 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 05:55:56 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.06191783
03-29 05:55:56 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.03033052
03-29 05:55:56 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.00196077
03-29 05:55:56 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.97629027
03-29 05:55:56 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.95378508
03-29 05:55:56 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.93540653
03-29 05:55:56 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.92170691
03-29 05:55:56 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.91491138
03-29 05:55:56 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.91964939
03-29 05:55:56 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.95256793
03-29 05:55:56 I loss/online/total: 9.66852659
03-29 05:56:14 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 05:56:17 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7740
03-29 05:56:17 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7768
03-29 05:56:17 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7796
03-29 05:56:17 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7827
03-29 05:56:17 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7867
03-29 05:56:17 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7885
03-29 05:56:17 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7905
03-29 05:56:17 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7927
03-29 05:56:17 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.7960
03-29 05:56:17 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.7941
03-29 05:56:17 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.7936000227928162 --> 0.7960000038146973
03-29 05:56:17 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 05:56:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 05:56:17 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.7882000207901001 --> 0.7941399812698364
03-29 05:56:17 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 05:56:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 05:56:17 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:04:09 I ------------------
03-29 06:04:09 I Epoch 5 (E5_U6255_S6405120)
03-29 06:04:09 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:04:09 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.15078084
03-29 06:04:09 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.10161735
03-29 06:04:09 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.05656841
03-29 06:04:09 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 1.01556406
03-29 06:04:09 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.97858438
03-29 06:04:09 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.94679796
03-29 06:04:09 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.92084141
03-29 06:04:09 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.90268625
03-29 06:04:09 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.89623167
03-29 06:04:09 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.91590727
03-29 06:04:09 I loss/online/total: 9.88557962
03-29 06:04:27 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 06:04:30 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7699
03-29 06:04:30 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7725
03-29 06:04:30 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7762
03-29 06:04:30 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7792
03-29 06:04:30 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7831
03-29 06:04:30 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7869
03-29 06:04:30 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7919
03-29 06:04:30 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7958
03-29 06:04:30 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.7981
03-29 06:04:30 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.7976
03-29 06:04:30 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7944200038909912 --> 0.7958400249481201
03-29 06:04:30 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 06:04:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 06:04:30 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.7960000038146973 --> 0.7980999946594238
03-29 06:04:30 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 06:04:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 06:04:30 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.7941399812698364 --> 0.7975999712944031
03-29 06:04:30 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:04:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:04:30 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:12:23 I ------------------
03-29 06:12:23 I Epoch 6 (E6_U7506_S7686144)
03-29 06:12:23 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:12:23 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.21251546
03-29 06:12:23 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.14927846
03-29 06:12:23 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.09275562
03-29 06:12:23 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 1.04082649
03-29 06:12:23 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.99372732
03-29 06:12:23 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.95309530
03-29 06:12:23 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.91909922
03-29 06:12:23 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.89336302
03-29 06:12:23 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.87962853
03-29 06:12:23 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.89106284
03-29 06:12:23 I loss/online/total: 10.02535225
03-29 06:12:40 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 06:12:42 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7707
03-29 06:12:43 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7743
03-29 06:12:43 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7768
03-29 06:12:43 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7814
03-29 06:12:43 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7865
03-29 06:12:43 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7893
03-29 06:12:43 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7936
03-29 06:12:43 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7983
03-29 06:12:43 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8018
03-29 06:12:43 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8021
03-29 06:12:43 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7935400009155273 --> 0.7935799956321716
03-29 06:12:43 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 06:12:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 06:12:43 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7958400249481201 --> 0.798259973526001
03-29 06:12:43 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 06:12:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 06:12:43 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.7980999946594238 --> 0.8018400073051453
03-29 06:12:43 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 06:12:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 06:12:43 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.7975999712944031 --> 0.8021399974822998
03-29 06:12:43 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:12:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:12:43 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:20:36 I ------------------
03-29 06:20:36 I Epoch 7 (E7_U8757_S8967168)
03-29 06:20:36 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:20:36 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.19755206
03-29 06:20:36 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.13551228
03-29 06:20:36 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.07774229
03-29 06:20:36 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 1.02335846
03-29 06:20:36 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.97559288
03-29 06:20:36 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.93414587
03-29 06:20:36 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.89931126
03-29 06:20:36 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.87276709
03-29 06:20:36 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.85794656
03-29 06:20:36 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.86718913
03-29 06:20:36 I loss/online/total: 9.84111790
03-29 06:20:53 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 06:20:56 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7719
03-29 06:20:56 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7749
03-29 06:20:56 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7784
03-29 06:20:56 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7822
03-29 06:20:56 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7863
03-29 06:20:56 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7905
03-29 06:20:56 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7944
03-29 06:20:56 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7985
03-29 06:20:56 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8017
03-29 06:20:56 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8026
03-29 06:20:56 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7935799956321716 --> 0.7944200038909912
03-29 06:20:56 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 06:20:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 06:20:56 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.798259973526001 --> 0.798520028591156
03-29 06:20:56 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 06:20:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 06:20:56 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8021399974822998 --> 0.802619993686676
03-29 06:20:56 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:20:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:20:56 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:28:49 I ------------------
03-29 06:28:49 I Epoch 8 (E8_U10008_S10248192)
03-29 06:28:49 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:28:49 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.18969110
03-29 06:28:49 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.12541502
03-29 06:28:49 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.06721643
03-29 06:28:49 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 1.01335923
03-29 06:28:49 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.96523671
03-29 06:28:49 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.92294291
03-29 06:28:49 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.88719019
03-29 06:28:49 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.85955247
03-29 06:28:49 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.84365304
03-29 06:28:49 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.85144055
03-29 06:28:49 I loss/online/total: 9.72569766
03-29 06:29:07 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 06:29:09 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7712
03-29 06:29:09 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7745
03-29 06:29:09 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7784
03-29 06:29:09 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7824
03-29 06:29:09 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7861
03-29 06:29:09 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7901
03-29 06:29:09 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7943
03-29 06:29:09 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7978
03-29 06:29:09 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8015
03-29 06:29:09 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8038
03-29 06:29:09 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.802619993686676 --> 0.8037800192832947
03-29 06:29:09 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:29:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:29:09 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:37:02 I ------------------
03-29 06:37:02 I Epoch 9 (E9_U11259_S11529216)
03-29 06:37:02 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:37:02 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.17711315
03-29 06:37:02 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.11420065
03-29 06:37:02 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.05566923
03-29 06:37:02 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 1.00201153
03-29 06:37:02 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.95411469
03-29 06:37:02 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.91210651
03-29 06:37:02 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.87662179
03-29 06:37:02 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.84910125
03-29 06:37:02 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.83289163
03-29 06:37:02 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.83965839
03-29 06:37:02 I loss/online/total: 9.61348882
03-29 06:37:20 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 06:37:22 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7711
03-29 06:37:22 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7746
03-29 06:37:22 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7783
03-29 06:37:22 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7824
03-29 06:37:22 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7865
03-29 06:37:22 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7902
03-29 06:37:22 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7943
03-29 06:37:22 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7980
03-29 06:37:22 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8020
03-29 06:37:22 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8045
03-29 06:37:22 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8018400073051453 --> 0.8019999861717224
03-29 06:37:22 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 06:37:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 06:37:22 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8037800192832947 --> 0.8045399785041809
03-29 06:37:22 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:37:23 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:37:23 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:45:15 I ------------------
03-29 06:45:15 I Epoch 10 (E10_U12510_S12810240)
03-29 06:45:15 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:45:15 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.16652492
03-29 06:45:15 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.10304170
03-29 06:45:15 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.04438811
03-29 06:45:15 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.99123858
03-29 06:45:15 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.94319396
03-29 06:45:15 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.90136151
03-29 06:45:15 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.86599496
03-29 06:45:15 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.83860376
03-29 06:45:15 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.82240059
03-29 06:45:15 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.82880946
03-29 06:45:15 I loss/online/total: 9.50555754
03-29 06:45:32 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 06:45:35 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7722
03-29 06:45:35 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7747
03-29 06:45:35 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7786
03-29 06:45:35 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7815
03-29 06:45:35 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7862
03-29 06:45:35 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7899
03-29 06:45:35 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7936
03-29 06:45:35 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7980
03-29 06:45:35 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8020
03-29 06:45:35 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8037
03-29 06:45:35 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8019999861717224 --> 0.8020200133323669
03-29 06:45:35 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 06:45:35 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 06:45:35 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 06:53:28 I ------------------
03-29 06:53:28 I Epoch 11 (E11_U13761_S14091264)
03-29 06:53:28 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 06:53:28 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.15737370
03-29 06:53:28 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.09481351
03-29 06:53:28 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.03801294
03-29 06:53:28 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.98434458
03-29 06:53:28 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.93676728
03-29 06:53:28 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.89497623
03-29 06:53:28 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.85968126
03-29 06:53:28 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.83208017
03-29 06:53:28 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.81548764
03-29 06:53:28 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.82119627
03-29 06:53:28 I loss/online/total: 9.43473358
03-29 06:53:45 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 06:53:47 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7736
03-29 06:53:47 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7764
03-29 06:53:47 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7796
03-29 06:53:47 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7824
03-29 06:53:47 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7866
03-29 06:53:47 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7915
03-29 06:53:47 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7951
03-29 06:53:47 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7990
03-29 06:53:47 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8030
03-29 06:53:47 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8056
03-29 06:53:47 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7910799980163574 --> 0.7915199995040894
03-29 06:53:47 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 06:53:47 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 06:53:47 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7944200038909912 --> 0.7950800061225891
03-29 06:53:48 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 06:53:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 06:53:48 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.798520028591156 --> 0.7990400195121765
03-29 06:53:48 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 06:53:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 06:53:48 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8020200133323669 --> 0.8030400276184082
03-29 06:53:48 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 06:53:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 06:53:48 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8045399785041809 --> 0.8056399822235107
03-29 06:53:48 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 06:53:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 06:53:48 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:01:40 I ------------------
03-29 07:01:40 I Epoch 12 (E12_U15012_S15372288)
03-29 07:01:40 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:01:40 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.14059802
03-29 07:01:40 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.07969283
03-29 07:01:40 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.02298928
03-29 07:01:40 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.97162870
03-29 07:01:40 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.92571737
03-29 07:01:40 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.88516349
03-29 07:01:40 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.85089441
03-29 07:01:40 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.82411249
03-29 07:01:40 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.80784534
03-29 07:01:40 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.81327346
03-29 07:01:40 I loss/online/total: 9.32191538
03-29 07:01:57 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 07:02:00 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7755
03-29 07:02:00 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7784
03-29 07:02:00 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7818
03-29 07:02:00 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7852
03-29 07:02:00 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7887
03-29 07:02:00 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7918
03-29 07:02:00 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7962
03-29 07:02:00 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7992
03-29 07:02:00 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8028
03-29 07:02:00 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8047
03-29 07:02:00 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7883800268173218 --> 0.7886599898338318
03-29 07:02:00 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 07:02:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 07:02:00 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7915199995040894 --> 0.7917600274085999
03-29 07:02:00 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 07:02:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 07:02:00 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7950800061225891 --> 0.7961999773979187
03-29 07:02:00 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 07:02:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 07:02:00 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7990400195121765 --> 0.7991999983787537
03-29 07:02:00 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 07:02:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 07:02:00 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:09:53 I ------------------
03-29 07:09:53 I Epoch 13 (E13_U16263_S16653312)
03-29 07:09:53 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:09:53 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.12743878
03-29 07:09:53 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.06831068
03-29 07:09:53 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.01272779
03-29 07:09:53 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.96205983
03-29 07:09:53 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.91681361
03-29 07:09:53 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.87689304
03-29 07:09:53 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.84317599
03-29 07:09:53 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.81671100
03-29 07:09:53 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.80061575
03-29 07:09:53 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.80577558
03-29 07:09:53 I loss/online/total: 9.23052207
03-29 07:10:10 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 07:10:12 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7726
03-29 07:10:12 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7764
03-29 07:10:12 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7799
03-29 07:10:12 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7832
03-29 07:10:12 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7860
03-29 07:10:12 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7907
03-29 07:10:12 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7940
03-29 07:10:12 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7991
03-29 07:10:12 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8026
03-29 07:10:12 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8065
03-29 07:10:12 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8056399822235107 --> 0.8065000176429749
03-29 07:10:12 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 07:10:12 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 07:10:12 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:18:05 I ------------------
03-29 07:18:05 I Epoch 14 (E14_U17514_S17934336)
03-29 07:18:05 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:18:05 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.11459615
03-29 07:18:05 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.05689269
03-29 07:18:05 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 1.00271233
03-29 07:18:05 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.95334990
03-29 07:18:05 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.90884031
03-29 07:18:05 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.86986487
03-29 07:18:05 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.83654829
03-29 07:18:05 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.81065934
03-29 07:18:05 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.79485349
03-29 07:18:05 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.80005044
03-29 07:18:05 I loss/online/total: 9.14836782
03-29 07:18:22 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 07:18:25 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7773
03-29 07:18:25 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7813
03-29 07:18:25 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7847
03-29 07:18:25 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7877
03-29 07:18:25 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7921
03-29 07:18:25 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7958
03-29 07:18:25 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7997
03-29 07:18:25 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8028
03-29 07:18:25 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8059
03-29 07:18:25 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8080
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7867199778556824 --> 0.7876999974250793
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7886599898338318 --> 0.7920600175857544
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7917600274085999 --> 0.795799970626831
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7961999773979187 --> 0.7996799945831299
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.7991999983787537 --> 0.8027799725532532
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8030400276184082 --> 0.8059399724006653
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 07:18:25 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8065000176429749 --> 0.8080400228500366
03-29 07:18:25 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 07:18:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 07:18:25 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:26:18 I ------------------
03-29 07:26:18 I Epoch 15 (E15_U18765_S19215360)
03-29 07:26:18 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:26:18 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.10326814
03-29 07:26:18 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.04647225
03-29 07:26:18 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.99393637
03-29 07:26:18 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.94602960
03-29 07:26:18 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.90279372
03-29 07:26:18 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.86466627
03-29 07:26:18 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.83207691
03-29 07:26:18 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.80637189
03-29 07:26:18 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.79072770
03-29 07:26:18 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.79595122
03-29 07:26:18 I loss/online/total: 9.08229406
03-29 07:26:35 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 07:26:38 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7752
03-29 07:26:38 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7792
03-29 07:26:38 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7820
03-29 07:26:38 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7856
03-29 07:26:38 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7896
03-29 07:26:38 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7941
03-29 07:26:38 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7980
03-29 07:26:38 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8022
03-29 07:26:38 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8051
03-29 07:26:38 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8077
03-29 07:26:38 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:34:31 I ------------------
03-29 07:34:31 I Epoch 16 (E16_U20016_S20496384)
03-29 07:34:31 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:34:31 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.08585205
03-29 07:34:31 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.03029168
03-29 07:34:31 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.97983663
03-29 07:34:31 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.93376768
03-29 07:34:31 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.89134396
03-29 07:34:31 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.85448175
03-29 07:34:31 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.82297433
03-29 07:34:31 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.79827391
03-29 07:34:31 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.78329664
03-29 07:34:31 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.78854250
03-29 07:34:31 I loss/online/total: 8.96866114
03-29 07:34:48 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 07:34:51 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7751
03-29 07:34:51 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7780
03-29 07:34:51 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7817
03-29 07:34:51 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7850
03-29 07:34:51 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7881
03-29 07:34:51 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7915
03-29 07:34:51 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7956
03-29 07:34:51 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.7999
03-29 07:34:51 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8041
03-29 07:34:51 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8078
03-29 07:34:51 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:42:44 I ------------------
03-29 07:42:44 I Epoch 17 (E17_U21267_S21777408)
03-29 07:42:44 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:42:44 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.06920755
03-29 07:42:44 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.01597657
03-29 07:42:44 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.96725904
03-29 07:42:44 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.92291592
03-29 07:42:44 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.88281978
03-29 07:42:44 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.84735161
03-29 07:42:44 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.81712341
03-29 07:42:44 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.79337594
03-29 07:42:44 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.77911381
03-29 07:42:44 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.78487720
03-29 07:42:44 I loss/online/total: 8.88002083
03-29 07:43:01 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 07:43:04 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7765
03-29 07:43:04 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7791
03-29 07:43:04 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7822
03-29 07:43:04 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7855
03-29 07:43:04 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7883
03-29 07:43:04 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7922
03-29 07:43:04 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7965
03-29 07:43:04 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8009
03-29 07:43:04 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8055
03-29 07:43:04 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8087
03-29 07:43:04 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8080400228500366 --> 0.8087000250816345
03-29 07:43:04 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 07:43:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 07:43:04 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:50:57 I ------------------
03-29 07:50:57 I Epoch 18 (E18_U22518_S23058432)
03-29 07:50:57 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:50:57 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.05207174
03-29 07:50:57 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 1.00191059
03-29 07:50:57 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.95542014
03-29 07:50:57 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.91249801
03-29 07:50:57 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.87413238
03-29 07:50:57 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.84004226
03-29 07:50:57 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.81109635
03-29 07:50:57 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.78852999
03-29 07:50:57 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.77519325
03-29 07:50:57 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.78167333
03-29 07:50:57 I loss/online/total: 8.79256804
03-29 07:51:14 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 07:51:17 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7813
03-29 07:51:17 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7832
03-29 07:51:17 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7861
03-29 07:51:17 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7891
03-29 07:51:17 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7931
03-29 07:51:17 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7957
03-29 07:51:17 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7989
03-29 07:51:17 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8025
03-29 07:51:17 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8046
03-29 07:51:17 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8084
03-29 07:51:17 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7856799960136414 --> 0.7860599756240845
03-29 07:51:17 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 07:51:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 07:51:17 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7876999974250793 --> 0.7890999913215637
03-29 07:51:17 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 07:51:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 07:51:17 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7920600175857544 --> 0.7930799722671509
03-29 07:51:17 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 07:51:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 07:51:17 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 07:59:10 I ------------------
03-29 07:59:10 I Epoch 19 (E19_U23769_S24339456)
03-29 07:59:10 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 07:59:10 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.03288131
03-29 07:59:10 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.98479622
03-29 07:59:10 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.94112642
03-29 07:59:10 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.90075784
03-29 07:59:10 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.86436050
03-29 07:59:10 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.83210379
03-29 07:59:10 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.80473494
03-29 07:59:10 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.78336997
03-29 07:59:10 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.77101908
03-29 07:59:10 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.77794487
03-29 07:59:10 I loss/online/total: 8.69309493
03-29 07:59:27 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 07:59:30 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7779
03-29 07:59:30 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7798
03-29 07:59:30 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7825
03-29 07:59:30 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7869
03-29 07:59:30 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7905
03-29 07:59:30 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7941
03-29 07:59:30 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7978
03-29 07:59:30 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8014
03-29 07:59:30 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8066
03-29 07:59:30 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8095
03-29 07:59:30 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8059399724006653 --> 0.8065800070762634
03-29 07:59:30 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 07:59:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 07:59:30 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8087000250816345 --> 0.8094599843025208
03-29 07:59:30 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 07:59:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 07:59:30 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:07:23 I ------------------
03-29 08:07:23 I Epoch 20 (E20_U25020_S25620480)
03-29 08:07:23 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:07:23 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 1.01356972
03-29 08:07:23 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.96787846
03-29 08:07:23 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.92590026
03-29 08:07:23 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.88715542
03-29 08:07:23 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.85258794
03-29 08:07:23 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.82202212
03-29 08:07:23 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.79600849
03-29 08:07:23 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.77578106
03-29 08:07:23 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.76409581
03-29 08:07:23 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.77159125
03-29 08:07:23 I loss/online/total: 8.57659054
03-29 08:07:40 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:07:43 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7787
03-29 08:07:43 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7819
03-29 08:07:43 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7847
03-29 08:07:43 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7878
03-29 08:07:43 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7915
03-29 08:07:43 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7950
03-29 08:07:43 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7994
03-29 08:07:43 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8031
03-29 08:07:43 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8070
03-29 08:07:43 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8085
03-29 08:07:43 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8027799725532532 --> 0.8031200170516968
03-29 08:07:43 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 08:07:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 08:07:43 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8065800070762634 --> 0.8070399761199951
03-29 08:07:43 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 08:07:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 08:07:43 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:15:36 I ------------------
03-29 08:15:36 I Epoch 21 (E21_U26271_S26901504)
03-29 08:15:36 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:15:36 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.99586296
03-29 08:15:36 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.95266917
03-29 08:15:36 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.91279670
03-29 08:15:36 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.87649589
03-29 08:15:36 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.84378026
03-29 08:15:36 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.81481845
03-29 08:15:36 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.79009188
03-29 08:15:36 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.77104555
03-29 08:15:36 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.76055798
03-29 08:15:36 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.76887245
03-29 08:15:36 I loss/online/total: 8.48699130
03-29 08:15:53 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 08:15:56 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7809
03-29 08:15:56 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7839
03-29 08:15:56 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7866
03-29 08:15:56 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7902
03-29 08:15:56 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7933
03-29 08:15:56 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7965
03-29 08:15:56 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7991
03-29 08:15:56 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8028
03-29 08:15:56 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8063
03-29 08:15:56 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8091
03-29 08:15:56 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7860599756240845 --> 0.7866399884223938
03-29 08:15:56 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 08:15:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 08:15:56 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7890999913215637 --> 0.7901800274848938
03-29 08:15:56 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 08:15:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 08:15:56 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7930799722671509 --> 0.7932599782943726
03-29 08:15:56 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 08:15:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 08:15:56 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.795799970626831 --> 0.7964800000190735
03-29 08:15:56 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 08:15:56 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 08:15:56 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:23:49 I ------------------
03-29 08:23:49 I Epoch 22 (E22_U27522_S28182528)
03-29 08:23:49 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:23:49 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.97410494
03-29 08:23:49 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.93438367
03-29 08:23:49 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.89686559
03-29 08:23:49 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.86282267
03-29 08:23:49 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.83214413
03-29 08:23:49 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.80527061
03-29 08:23:49 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.78251220
03-29 08:23:49 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.76505725
03-29 08:23:49 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.75568392
03-29 08:23:49 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.76490283
03-29 08:23:49 I loss/online/total: 8.37374781
03-29 08:24:06 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:24:09 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7826
03-29 08:24:09 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7852
03-29 08:24:09 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7879
03-29 08:24:09 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7916
03-29 08:24:09 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7943
03-29 08:24:09 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7971
03-29 08:24:09 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8003
03-29 08:24:09 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8032
03-29 08:24:09 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8060
03-29 08:24:09 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8086
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7845799922943115 --> 0.7852200269699097
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7866399884223938 --> 0.787880003452301
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7901800274848938 --> 0.7916200160980225
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7932599782943726 --> 0.7943199872970581
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7964800000190735 --> 0.7971000075340271
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.7996799945831299 --> 0.800320029258728
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 08:24:09 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8031200170516968 --> 0.8031799793243408
03-29 08:24:09 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 08:24:09 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 08:24:09 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:32:02 I ------------------
03-29 08:32:02 I Epoch 23 (E23_U28773_S29463552)
03-29 08:32:02 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:32:02 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.96066984
03-29 08:32:02 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.92228322
03-29 08:32:02 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.88753013
03-29 08:32:02 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.85560344
03-29 08:32:02 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.82656759
03-29 08:32:02 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.80099204
03-29 08:32:02 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.77927915
03-29 08:32:02 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.76267292
03-29 08:32:02 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.75403253
03-29 08:32:02 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.76362081
03-29 08:32:02 I loss/online/total: 8.31325167
03-29 08:32:19 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:32:22 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7858
03-29 08:32:22 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7881
03-29 08:32:22 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7914
03-29 08:32:22 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7940
03-29 08:32:22 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7975
03-29 08:32:22 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8002
03-29 08:32:22 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8029
03-29 08:32:22 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8047
03-29 08:32:22 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8078
03-29 08:32:22 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8102
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7827200293540955 --> 0.7857599854469299
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7852200269699097 --> 0.7881399989128113
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.787880003452301 --> 0.7914199829101562
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7916200160980225 --> 0.7939599752426147
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7943199872970581 --> 0.797540009021759
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.7971000075340271 --> 0.8001599907875061
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.800320029258728 --> 0.8028799891471863
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8031799793243408 --> 0.8047400116920471
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8070399761199951 --> 0.8077999949455261
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 08:32:22 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8094599843025208 --> 0.8101599812507629
03-29 08:32:22 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 08:32:22 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 08:32:22 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:40:15 I ------------------
03-29 08:40:15 I Epoch 24 (E24_U30024_S30744576)
03-29 08:40:15 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:40:15 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.93909477
03-29 08:40:15 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.90404822
03-29 08:40:15 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.87130704
03-29 08:40:15 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.84170744
03-29 08:40:15 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.81488371
03-29 08:40:15 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.79105921
03-29 08:40:15 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.77106115
03-29 08:40:15 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.75594270
03-29 08:40:15 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.74872902
03-29 08:40:15 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.75933084
03-29 08:40:15 I loss/online/total: 8.19716411
03-29 08:40:32 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:40:35 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7833
03-29 08:40:35 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7854
03-29 08:40:35 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7883
03-29 08:40:35 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7913
03-29 08:40:35 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7939
03-29 08:40:35 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7972
03-29 08:40:35 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.7995
03-29 08:40:35 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8025
03-29 08:40:35 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8060
03-29 08:40:35 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8091
03-29 08:40:35 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:48:28 I ------------------
03-29 08:48:28 I Epoch 25 (E25_U31275_S32025600)
03-29 08:48:28 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:48:28 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.92066608
03-29 08:48:28 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.88790996
03-29 08:48:28 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.85761415
03-29 08:48:28 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.82986455
03-29 08:48:28 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.80466604
03-29 08:48:28 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.78269308
03-29 08:48:28 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.76413084
03-29 08:48:28 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.75017953
03-29 08:48:28 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.74374048
03-29 08:48:28 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.75506701
03-29 08:48:28 I loss/online/total: 8.09653172
03-29 08:48:45 I accuracy_logger_test_iter=0.01 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:48:48 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7869
03-29 08:48:48 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7893
03-29 08:48:48 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7913
03-29 08:48:48 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7936
03-29 08:48:48 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7962
03-29 08:48:48 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.7992
03-29 08:48:48 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8021
03-29 08:48:48 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8043
03-29 08:48:48 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8074
03-29 08:48:48 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8092
03-29 08:48:48 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7857599854469299 --> 0.786899983882904
03-29 08:48:48 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 08:48:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 08:48:48 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7881399989128113 --> 0.7892799973487854
03-29 08:48:48 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 08:48:48 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 08:48:48 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 08:56:41 I ------------------
03-29 08:56:41 I Epoch 26 (E26_U32526_S33306624)
03-29 08:56:41 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 08:56:41 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.90328653
03-29 08:56:41 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.87315450
03-29 08:56:41 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.84518367
03-29 08:56:41 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.81978055
03-29 08:56:41 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.79688121
03-29 08:56:41 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.77665931
03-29 08:56:41 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.75968798
03-29 08:56:41 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.74718444
03-29 08:56:41 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.74188938
03-29 08:56:41 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.75413703
03-29 08:56:41 I loss/online/total: 8.01784461
03-29 08:56:58 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 08:57:01 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7867
03-29 08:57:01 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7892
03-29 08:57:01 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7918
03-29 08:57:01 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7947
03-29 08:57:01 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7974
03-29 08:57:01 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8003
03-29 08:57:01 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8032
03-29 08:57:01 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8057
03-29 08:57:01 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8091
03-29 08:57:01 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8106
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7914199829101562 --> 0.7918199896812439
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7939599752426147 --> 0.7947400212287903
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8001599907875061 --> 0.800279974937439
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8028799891471863 --> 0.8032199740409851
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8047400116920471 --> 0.8057199716567993
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8077999949455261 --> 0.8090599775314331
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 08:57:01 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8101599812507629 --> 0.8105599880218506
03-29 08:57:01 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 08:57:01 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 08:57:01 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:04:55 I ------------------
03-29 09:04:55 I Epoch 27 (E27_U33777_S34587648)
03-29 09:04:55 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:04:55 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.88641074
03-29 09:04:55 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.85854131
03-29 09:04:55 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.83288363
03-29 09:04:55 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.80939260
03-29 09:04:55 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.78824543
03-29 09:04:55 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.76967342
03-29 09:04:55 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.75422109
03-29 09:04:55 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.74313525
03-29 09:04:55 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.73913289
03-29 09:04:55 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.75227132
03-29 09:04:55 I loss/online/total: 7.93390768
03-29 09:05:12 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:05:15 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7900
03-29 09:05:15 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7919
03-29 09:05:15 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7937
03-29 09:05:15 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7963
03-29 09:05:15 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7986
03-29 09:05:15 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8007
03-29 09:05:15 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8027
03-29 09:05:15 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8044
03-29 09:05:15 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8072
03-29 09:05:15 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8096
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.786899983882904 --> 0.7900199890136719
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7892799973487854 --> 0.7918599843978882
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7918199896812439 --> 0.7937399744987488
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7947400212287903 --> 0.796280026435852
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.797540009021759 --> 0.7985799908638
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:05:15 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.800279974937439 --> 0.8007199764251709
03-29 09:05:15 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 09:05:15 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 09:05:15 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:13:08 I ------------------
03-29 09:13:08 I Epoch 28 (E28_U35028_S35868672)
03-29 09:13:08 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:13:08 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.86716871
03-29 09:13:08 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.84189656
03-29 09:13:08 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.81845928
03-29 09:13:08 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.79705200
03-29 09:13:08 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.77774428
03-29 09:13:08 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.76085401
03-29 09:13:08 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.74693133
03-29 09:13:08 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.73712193
03-29 09:13:08 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.73430488
03-29 09:13:08 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.74866223
03-29 09:13:08 I loss/online/total: 7.83019521
03-29 09:13:26 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:13:28 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7892
03-29 09:13:28 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7918
03-29 09:13:28 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7945
03-29 09:13:28 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7971
03-29 09:13:28 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7996
03-29 09:13:28 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8019
03-29 09:13:28 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8046
03-29 09:13:28 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8065
03-29 09:13:28 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8081
03-29 09:13:28 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8102
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7937399744987488 --> 0.7944599986076355
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.796280026435852 --> 0.7970799803733826
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7985799908638 --> 0.7995799779891968
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8007199764251709 --> 0.8019000291824341
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8032199740409851 --> 0.8045799732208252
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 09:13:28 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8057199716567993 --> 0.8065199851989746
03-29 09:13:28 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 09:13:28 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 09:13:28 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:21:21 I ------------------
03-29 09:21:21 I Epoch 29 (E29_U36279_S37149696)
03-29 09:21:21 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:21:21 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.84497269
03-29 09:21:21 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.82212619
03-29 09:21:21 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.80116654
03-29 09:21:21 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.78208540
03-29 09:21:21 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.76496366
03-29 09:21:21 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.75004719
03-29 09:21:21 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.73792120
03-29 09:21:21 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.72961670
03-29 09:21:21 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.72812999
03-29 09:21:21 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.74351643
03-29 09:21:21 I loss/online/total: 7.70454599
03-29 09:21:39 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 09:21:42 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7905
03-29 09:21:42 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7928
03-29 09:21:42 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7947
03-29 09:21:42 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7971
03-29 09:21:42 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7988
03-29 09:21:42 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8017
03-29 09:21:42 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8050
03-29 09:21:42 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8070
03-29 09:21:42 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8089
03-29 09:21:42 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8101
03-29 09:21:42 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7900199890136719 --> 0.7904800176620483
03-29 09:21:42 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 09:21:42 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 09:21:42 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7918599843978882 --> 0.7927799820899963
03-29 09:21:42 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 09:21:42 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 09:21:42 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7944599986076355 --> 0.794700026512146
03-29 09:21:42 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:21:42 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:21:42 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8045799732208252 --> 0.8050400018692017
03-29 09:21:42 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 09:21:42 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 09:21:42 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8065199851989746 --> 0.8070200085639954
03-29 09:21:42 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 09:21:42 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 09:21:42 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:29:35 I ------------------
03-29 09:29:35 I Epoch 30 (E30_U37530_S38430720)
03-29 09:29:35 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:29:35 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.83452338
03-29 09:29:35 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.81375024
03-29 09:29:35 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.79465289
03-29 09:29:35 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.77717850
03-29 09:29:35 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.76152012
03-29 09:29:35 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.74791404
03-29 09:29:35 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.73691703
03-29 09:29:35 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.72967421
03-29 09:29:35 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.72902105
03-29 09:29:35 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.74507581
03-29 09:29:35 I loss/online/total: 7.67022727
03-29 09:29:52 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:29:55 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7919
03-29 09:29:55 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7943
03-29 09:29:55 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7959
03-29 09:29:55 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7975
03-29 09:29:55 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.7997
03-29 09:29:55 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8013
03-29 09:29:55 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8033
03-29 09:29:55 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8059
03-29 09:29:55 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8080
03-29 09:29:55 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8101
03-29 09:29:55 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7904800176620483 --> 0.791920006275177
03-29 09:29:55 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 09:29:55 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 09:29:55 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7927799820899963 --> 0.7943400144577026
03-29 09:29:55 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 09:29:55 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 09:29:55 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.794700026512146 --> 0.7958800196647644
03-29 09:29:55 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:29:55 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:29:55 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7970799803733826 --> 0.797540009021759
03-29 09:29:55 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:29:55 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:29:55 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7995799779891968 --> 0.7997000217437744
03-29 09:29:55 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:29:55 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:29:55 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:37:48 I ------------------
03-29 09:37:48 I Epoch 31 (E31_U38781_S39711744)
03-29 09:37:48 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:37:48 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.81579289
03-29 09:37:48 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.79727759
03-29 09:37:48 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.78026382
03-29 09:37:48 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.76472632
03-29 09:37:48 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.75091382
03-29 09:37:48 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.73893948
03-29 09:37:48 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.72951890
03-29 09:37:48 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.72366073
03-29 09:37:48 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.72421485
03-29 09:37:48 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.74137544
03-29 09:37:48 I loss/online/total: 7.56668383
03-29 09:38:06 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:38:08 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7918
03-29 09:38:08 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7933
03-29 09:38:08 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7953
03-29 09:38:08 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.7977
03-29 09:38:08 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8001
03-29 09:38:08 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8026
03-29 09:38:08 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8042
03-29 09:38:08 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8064
03-29 09:38:08 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8089
03-29 09:38:08 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8100
03-29 09:38:08 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.797540009021759 --> 0.7976800203323364
03-29 09:38:08 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:38:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:38:08 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.7997000217437744 --> 0.8001400232315063
03-29 09:38:08 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:38:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:38:08 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8019000291824341 --> 0.8026000261306763
03-29 09:38:08 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 09:38:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 09:38:08 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:46:01 I ------------------
03-29 09:46:01 I Epoch 32 (E32_U40032_S40992768)
03-29 09:46:01 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:46:01 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.79998743
03-29 09:46:01 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.78343151
03-29 09:46:01 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.76815640
03-29 09:46:01 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.75428746
03-29 09:46:01 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.74188449
03-29 09:46:01 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.73135872
03-29 09:46:01 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.72308870
03-29 09:46:01 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.71834170
03-29 09:46:01 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.71979223
03-29 09:46:01 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73776561
03-29 09:46:01 I loss/online/total: 7.47809423
03-29 09:46:19 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:46:21 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7958
03-29 09:46:21 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7975
03-29 09:46:21 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7989
03-29 09:46:21 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8001
03-29 09:46:21 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8022
03-29 09:46:21 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8039
03-29 09:46:21 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8058
03-29 09:46:21 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8076
03-29 09:46:21 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8097
03-29 09:46:21 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8110
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.791920006275177 --> 0.7958199977874756
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7943400144577026 --> 0.7975000143051147
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7958800196647644 --> 0.7988799810409546
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.7976800203323364 --> 0.800059974193573
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8001400232315063 --> 0.8021600246429443
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8026000261306763 --> 0.8039399981498718
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8050400018692017 --> 0.805840015411377
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8070200085639954 --> 0.8075600266456604
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8090599775314331 --> 0.809660017490387
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 09:46:21 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8105599880218506 --> 0.8109800219535828
03-29 09:46:21 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 09:46:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 09:46:21 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 09:54:14 I ------------------
03-29 09:54:14 I Epoch 33 (E33_U41283_S42273792)
03-29 09:54:14 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 09:54:14 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.78685035
03-29 09:54:14 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.77195655
03-29 09:54:14 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.75836027
03-29 09:54:14 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.74596807
03-29 09:54:14 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.73515870
03-29 09:54:14 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.72595308
03-29 09:54:14 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.71901433
03-29 09:54:14 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.71546172
03-29 09:54:14 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.71805293
03-29 09:54:14 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73698197
03-29 09:54:14 I loss/online/total: 7.41375797
03-29 09:54:32 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 09:54:34 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7968
03-29 09:54:34 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7988
03-29 09:54:34 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7999
03-29 09:54:34 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8012
03-29 09:54:34 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8034
03-29 09:54:34 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8053
03-29 09:54:34 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8068
03-29 09:54:34 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8090
03-29 09:54:34 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8101
03-29 09:54:34 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8107
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7958199977874756 --> 0.7967600226402283
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7975000143051147 --> 0.7987599968910217
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7988799810409546 --> 0.7998999953269958
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.800059974193573 --> 0.8011999726295471
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8021600246429443 --> 0.8034200072288513
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8039399981498718 --> 0.8053200244903564
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.805840015411377 --> 0.8068400025367737
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8075600266456604 --> 0.8089799880981445
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 09:54:34 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.809660017490387 --> 0.8101400136947632
03-29 09:54:34 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 09:54:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 09:54:34 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:02:27 I ------------------
03-29 10:02:27 I Epoch 34 (E34_U42534_S43554816)
03-29 10:02:27 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:02:27 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.77609267
03-29 10:02:27 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.76298376
03-29 10:02:27 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.75096473
03-29 10:02:27 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.74012862
03-29 10:02:27 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.73057211
03-29 10:02:27 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.72264912
03-29 10:02:27 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.71676124
03-29 10:02:27 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.71419387
03-29 10:02:27 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.71772368
03-29 10:02:27 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73766660
03-29 10:02:27 I loss/online/total: 7.36973640
03-29 10:02:44 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 10:02:47 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7958
03-29 10:02:47 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.7976
03-29 10:02:47 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.7992
03-29 10:02:47 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8009
03-29 10:02:47 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8025
03-29 10:02:47 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8042
03-29 10:02:47 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8061
03-29 10:02:47 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8082
03-29 10:02:47 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8094
03-29 10:02:47 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8109
03-29 10:02:47 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:10:40 I ------------------
03-29 10:10:40 I Epoch 35 (E35_U43785_S44835840)
03-29 10:10:40 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:10:40 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.76137800
03-29 10:10:40 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.74988654
03-29 10:10:40 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.73939526
03-29 10:10:40 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.72997032
03-29 10:10:40 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.72178653
03-29 10:10:40 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.71516937
03-29 10:10:40 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.71054516
03-29 10:10:40 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.70906101
03-29 10:10:40 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.71362093
03-29 10:10:40 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73435928
03-29 10:10:40 I loss/online/total: 7.28517238
03-29 10:10:57 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 10:10:59 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7988
03-29 10:10:59 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8005
03-29 10:10:59 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8018
03-29 10:10:59 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8029
03-29 10:10:59 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8040
03-29 10:10:59 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8058
03-29 10:10:59 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8076
03-29 10:10:59 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8087
03-29 10:10:59 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8095
03-29 10:10:59 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8113
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7967600226402283 --> 0.7988399863243103
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.7987599968910217 --> 0.8004599809646606
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.7998999953269958 --> 0.8017600178718567
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8011999726295471 --> 0.8029199838638306
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8034200072288513 --> 0.8040400147438049
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8053200244903564 --> 0.8058000206947327
03-29 10:10:59 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 10:10:59 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 10:10:59 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8068400025367737 --> 0.8076199889183044
03-29 10:11:00 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 10:11:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 10:11:00 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8109800219535828 --> 0.8112999796867371
03-29 10:11:00 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 10:11:00 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 10:11:00 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:18:52 I ------------------
03-29 10:18:52 I Epoch 36 (E36_U45036_S46116864)
03-29 10:18:52 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:18:52 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.74728466
03-29 10:18:52 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.73738739
03-29 10:18:52 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.72835214
03-29 10:18:52 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.72028247
03-29 10:18:52 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.71340157
03-29 10:18:52 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.70794803
03-29 10:18:52 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.70445606
03-29 10:18:52 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.70409034
03-29 10:18:52 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70960554
03-29 10:18:52 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73108860
03-29 10:18:52 I loss/online/total: 7.20389680
03-29 10:19:09 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 10:19:12 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7992
03-29 10:19:12 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8002
03-29 10:19:12 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8009
03-29 10:19:12 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8023
03-29 10:19:12 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8040
03-29 10:19:12 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8052
03-29 10:19:12 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8069
03-29 10:19:12 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8091
03-29 10:19:12 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8103
03-29 10:19:12 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8112
03-29 10:19:12 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7988399863243103 --> 0.7991999983787537
03-29 10:19:12 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 10:19:12 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 10:19:12 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8089799880981445 --> 0.8091400265693665
03-29 10:19:12 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 10:19:12 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 10:19:12 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8101400136947632 --> 0.810259997844696
03-29 10:19:12 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 10:19:12 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 10:19:12 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:27:05 I ------------------
03-29 10:27:05 I Epoch 37 (E37_U46287_S47397888)
03-29 10:27:05 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:27:05 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.73699810
03-29 10:27:05 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.72837211
03-29 10:27:05 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.72056215
03-29 10:27:05 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.71368099
03-29 10:27:05 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.70790239
03-29 10:27:05 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.70346666
03-29 10:27:05 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.70095554
03-29 10:27:05 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.70143629
03-29 10:27:05 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70786942
03-29 10:27:05 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73025002
03-29 10:27:05 I loss/online/total: 7.15149367
03-29 10:27:23 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 10:27:25 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7985
03-29 10:27:25 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8002
03-29 10:27:25 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8019
03-29 10:27:25 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8033
03-29 10:27:25 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8051
03-29 10:27:25 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8060
03-29 10:27:25 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8075
03-29 10:27:25 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8095
03-29 10:27:25 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8102
03-29 10:27:25 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8115
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8017600178718567 --> 0.8019000291824341
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8029199838638306 --> 0.8032600283622742
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8040400147438049 --> 0.8051000237464905
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8058000206947327 --> 0.8059999942779541
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8091400265693665 --> 0.8094599843025208
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 10:27:25 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8112999796867371 --> 0.811460018157959
03-29 10:27:25 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 10:27:25 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 10:27:25 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:35:18 I ------------------
03-29 10:35:18 I Epoch 38 (E38_U47538_S48678912)
03-29 10:35:18 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:35:18 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.72867554
03-29 10:35:18 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.72122115
03-29 10:35:18 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.71448556
03-29 10:35:18 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.70862579
03-29 10:35:18 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.70382133
03-29 10:35:18 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.70032540
03-29 10:35:18 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.69864291
03-29 10:35:18 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.69998155
03-29 10:35:18 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70716389
03-29 10:35:18 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73035952
03-29 10:35:18 I loss/online/total: 7.11330263
03-29 10:35:35 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 10:35:38 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.7998
03-29 10:35:38 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8012
03-29 10:35:38 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8020
03-29 10:35:38 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8037
03-29 10:35:38 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8047
03-29 10:35:38 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8058
03-29 10:35:38 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8083
03-29 10:35:38 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8095
03-29 10:35:38 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8112
03-29 10:35:38 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8117
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7991999983787537 --> 0.7997599840164185
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8004599809646606 --> 0.8011599779129028
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8019000291824341 --> 0.8020200133323669
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8032600283622742 --> 0.803659975528717
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8076199889183044 --> 0.8083199858665466
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8094599843025208 --> 0.8095200061798096
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.810259997844696 --> 0.8112199902534485
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 10:35:38 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.811460018157959 --> 0.8116599917411804
03-29 10:35:38 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 10:35:38 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 10:35:38 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:43:31 I ------------------
03-29 10:43:31 I Epoch 39 (E39_U48789_S49959936)
03-29 10:43:31 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:43:31 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.72008849
03-29 10:43:31 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.71373187
03-29 10:43:31 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.70808673
03-29 10:43:31 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.70332614
03-29 10:43:31 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.69942506
03-29 10:43:31 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.69685855
03-29 10:43:31 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.69608161
03-29 10:43:31 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.69822313
03-29 10:43:31 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70617667
03-29 10:43:31 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.73003547
03-29 10:43:31 I loss/online/total: 7.07203375
03-29 10:43:48 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 10:43:50 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8029
03-29 10:43:50 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8031
03-29 10:43:50 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8041
03-29 10:43:50 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8049
03-29 10:43:51 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8065
03-29 10:43:51 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8076
03-29 10:43:51 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8090
03-29 10:43:51 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8102
03-29 10:43:51 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8114
03-29 10:43:51 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8120
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.7997599840164185 --> 0.8029199838638306
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8011599779129028 --> 0.8031200170516968
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8020200133323669 --> 0.8041200041770935
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.803659975528717 --> 0.8049200177192688
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8051000237464905 --> 0.8064799904823303
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8059999942779541 --> 0.8076000213623047
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8083199858665466 --> 0.8090400099754333
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8095200061798096 --> 0.8101800084114075
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8112199902534485 --> 0.8114399909973145
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 10:43:51 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8116599917411804 --> 0.8119999766349792
03-29 10:43:51 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 10:43:51 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 10:43:51 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:51:44 I ------------------
03-29 10:51:44 I Epoch 40 (E40_U50040_S51240960)
03-29 10:51:44 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:51:44 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.71219856
03-29 10:51:44 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.70671185
03-29 10:51:44 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.70192430
03-29 10:51:44 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.69794182
03-29 10:51:44 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.69488860
03-29 10:51:44 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.69302793
03-29 10:51:44 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.69293992
03-29 10:51:44 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.69582347
03-29 10:51:44 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70437100
03-29 10:51:44 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72889216
03-29 10:51:44 I loss/online/total: 7.02871961
03-29 10:52:01 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 10:52:04 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8030
03-29 10:52:04 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8039
03-29 10:52:04 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8045
03-29 10:52:04 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8053
03-29 10:52:04 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8066
03-29 10:52:04 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8073
03-29 10:52:04 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8079
03-29 10:52:04 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8096
03-29 10:52:04 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8103
03-29 10:52:04 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8115
03-29 10:52:04 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.8029199838638306 --> 0.8029599785804749
03-29 10:52:04 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 10:52:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 10:52:04 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8031200170516968 --> 0.8039000034332275
03-29 10:52:04 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 10:52:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 10:52:04 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8041200041770935 --> 0.8044999837875366
03-29 10:52:04 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 10:52:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 10:52:04 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8049200177192688 --> 0.8052600026130676
03-29 10:52:04 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 10:52:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 10:52:04 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8064799904823303 --> 0.8066400289535522
03-29 10:52:04 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 10:52:04 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 10:52:04 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 10:59:57 I ------------------
03-29 10:59:57 I Epoch 41 (E41_U51291_S52521984)
03-29 10:59:57 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 10:59:57 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.70196835
03-29 10:59:57 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.69743019
03-29 10:59:57 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.69356986
03-29 10:59:57 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.69047153
03-29 10:59:57 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.68824525
03-29 10:59:57 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.68725131
03-29 10:59:57 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.68795616
03-29 10:59:57 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.69163875
03-29 10:59:57 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70097593
03-29 10:59:57 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72631022
03-29 10:59:57 I loss/online/total: 6.96581755
03-29 11:00:14 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 11:00:17 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8041
03-29 11:00:17 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8051
03-29 11:00:17 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8059
03-29 11:00:17 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8064
03-29 11:00:17 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8074
03-29 11:00:17 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8082
03-29 11:00:17 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8095
03-29 11:00:17 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8108
03-29 11:00:17 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8118
03-29 11:00:17 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8118
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.8029599785804749 --> 0.8040599822998047
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8039000034332275 --> 0.805079996585846
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8044999837875366 --> 0.8059399724006653
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8052600026130676 --> 0.8064000010490417
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8066400289535522 --> 0.8073599934577942
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8076000213623047 --> 0.8082399964332581
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8090400099754333 --> 0.809499979019165
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8101800084114075 --> 0.8107799887657166
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 11:00:17 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8114399909973145 --> 0.8117799758911133
03-29 11:00:17 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 11:00:17 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 11:00:17 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:08:10 I ------------------
03-29 11:08:10 I Epoch 42 (E42_U52542_S53803008)
03-29 11:08:10 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:08:10 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.69655370
03-29 11:08:10 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.69278609
03-29 11:08:10 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.68964819
03-29 11:08:10 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.68724739
03-29 11:08:10 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.68571065
03-29 11:08:10 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.68535482
03-29 11:08:10 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.68671626
03-29 11:08:10 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.69094779
03-29 11:08:10 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.70093946
03-29 11:08:10 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72674745
03-29 11:08:10 I loss/online/total: 6.94265179
03-29 11:08:28 I accuracy_logger_test_iter=0.01 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 11:08:30 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8033
03-29 11:08:30 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8041
03-29 11:08:30 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8053
03-29 11:08:30 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8059
03-29 11:08:30 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8071
03-29 11:08:30 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8084
03-29 11:08:30 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8096
03-29 11:08:30 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8109
03-29 11:08:30 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8119
03-29 11:08:30 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8119
03-29 11:08:30 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8082399964332581 --> 0.8083599805831909
03-29 11:08:30 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 11:08:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 11:08:30 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.809499979019165 --> 0.8095999956130981
03-29 11:08:30 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 11:08:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 11:08:30 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8107799887657166 --> 0.8108800053596497
03-29 11:08:30 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 11:08:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 11:08:30 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8117799758911133 --> 0.8118799924850464
03-29 11:08:30 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 11:08:30 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 11:08:30 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:16:23 I ------------------
03-29 11:16:23 I Epoch 43 (E43_U53793_S55084032)
03-29 11:16:23 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:16:23 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.68931860
03-29 11:16:23 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.68617585
03-29 11:16:23 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.68364489
03-29 11:16:23 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.68181505
03-29 11:16:23 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.68090357
03-29 11:16:23 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.68113269
03-29 11:16:23 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.68306290
03-29 11:16:23 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68786120
03-29 11:16:23 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69839989
03-29 11:16:23 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72491491
03-29 11:16:23 I loss/online/total: 6.89722956
03-29 11:16:40 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 11:16:43 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8042
03-29 11:16:43 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8053
03-29 11:16:43 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8062
03-29 11:16:43 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8070
03-29 11:16:43 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8078
03-29 11:16:43 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8088
03-29 11:16:43 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8100
03-29 11:16:43 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8110
03-29 11:16:43 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8121
03-29 11:16:43 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8125
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.8040599822998047 --> 0.8041800260543823
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.805079996585846 --> 0.8052999973297119
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8059399724006653 --> 0.8062400221824646
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8064000010490417 --> 0.8069800138473511
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8073599934577942 --> 0.8077600002288818
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8083599805831909 --> 0.8087599873542786
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8095999956130981 --> 0.8100200295448303
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8108800053596497 --> 0.8109999895095825
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr002_wupcos_wd0_default): 0.8118799924850464 --> 0.8120800256729126
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr002_wupcos_wd0_default.th
03-29 11:16:43 I new best model (accuracy1/test/cls_sgd_lr001_wupcos_wd0_default): 0.8119999766349792 --> 0.8124600052833557
03-29 11:16:43 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default model.th
03-29 11:16:43 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr001_wupcos_wd0_default.th
03-29 11:16:43 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:24:36 I ------------------
03-29 11:24:36 I Epoch 44 (E44_U55044_S56365056)
03-29 11:24:36 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:24:36 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.68551225
03-29 11:24:36 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.68291195
03-29 11:24:36 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.68089629
03-29 11:24:36 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.67954736
03-29 11:24:36 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.67910778
03-29 11:24:36 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67982201
03-29 11:24:36 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.68215756
03-29 11:24:36 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68737192
03-29 11:24:36 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69831954
03-29 11:24:36 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72504649
03-29 11:24:36 I loss/online/total: 6.88069316
03-29 11:24:53 I accuracy_logger_test_iter=0.01 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 11:24:55 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8034
03-29 11:24:55 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8041
03-29 11:24:55 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8055
03-29 11:24:55 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8059
03-29 11:24:55 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8070
03-29 11:24:55 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8084
03-29 11:24:55 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8093
03-29 11:24:55 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8102
03-29 11:24:55 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8113
03-29 11:24:55 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8121
03-29 11:24:55 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:32:48 I ------------------
03-29 11:32:48 I Epoch 45 (E45_U56295_S57646080)
03-29 11:32:48 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:32:48 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.68232113
03-29 11:32:48 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.68012110
03-29 11:32:48 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.67852944
03-29 11:32:48 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.67764019
03-29 11:32:48 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.67754639
03-29 11:32:48 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67863250
03-29 11:32:48 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.68136851
03-29 11:32:48 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68697100
03-29 11:32:48 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69823865
03-29 11:32:48 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72519969
03-29 11:32:48 I loss/online/total: 6.86656860
03-29 11:33:05 I accuracy_logger_test_iter=0.01 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 11:33:08 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8046
03-29 11:33:08 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8056
03-29 11:33:08 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8060
03-29 11:33:08 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8063
03-29 11:33:08 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8077
03-29 11:33:08 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8089
03-29 11:33:08 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8094
03-29 11:33:08 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8102
03-29 11:33:08 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8117
03-29 11:33:08 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8121
03-29 11:33:08 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.8041800260543823 --> 0.804639995098114
03-29 11:33:08 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 11:33:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 11:33:08 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8052999973297119 --> 0.805620014667511
03-29 11:33:08 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 11:33:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 11:33:08 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.8087599873542786 --> 0.808899998664856
03-29 11:33:08 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 11:33:08 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 11:33:08 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:41:01 I ------------------
03-29 11:41:01 I Epoch 46 (E46_U57546_S58927104)
03-29 11:41:01 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:41:01 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.67719653
03-29 11:41:01 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.67538676
03-29 11:41:01 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.67416552
03-29 11:41:01 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.67364348
03-29 11:41:01 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.67393395
03-29 11:41:01 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67538100
03-29 11:41:01 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.67853285
03-29 11:41:01 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68447673
03-29 11:41:01 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69611615
03-29 11:41:01 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72355563
03-29 11:41:01 I loss/online/total: 6.83238860
03-29 11:41:19 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 11:41:21 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8055
03-29 11:41:21 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8063
03-29 11:41:21 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8069
03-29 11:41:21 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8076
03-29 11:41:21 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8089
03-29 11:41:21 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8096
03-29 11:41:21 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8104
03-29 11:41:21 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8108
03-29 11:41:21 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8119
03-29 11:41:21 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8122
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.804639995098114 --> 0.8054999709129333
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.805620014667511 --> 0.8063200116157532
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8062400221824646 --> 0.8069199919700623
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.8069800138473511 --> 0.807640016078949
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr006_wupcos_wd0_default): 0.8077600002288818 --> 0.8089399933815002
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr006_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr005_wupcos_wd0_default): 0.808899998664856 --> 0.8095600008964539
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr005_wupcos_wd0_default.th
03-29 11:41:21 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8100200295448303 --> 0.8104199767112732
03-29 11:41:21 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 11:41:21 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 11:41:21 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:49:14 I ------------------
03-29 11:49:14 I Epoch 47 (E47_U58797_S60208128)
03-29 11:49:14 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:49:14 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.67369606
03-29 11:49:14 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.67223398
03-29 11:49:14 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.67130096
03-29 11:49:14 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.67106543
03-29 11:49:14 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.67167729
03-29 11:49:14 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67341347
03-29 11:49:14 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.67687791
03-29 11:49:14 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68316300
03-29 11:49:14 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69514069
03-29 11:49:14 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72304302
03-29 11:49:14 I loss/online/total: 6.81161181
03-29 11:49:31 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 11:49:34 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8058
03-29 11:49:34 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8069
03-29 11:49:34 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8075
03-29 11:49:34 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8080
03-29 11:49:34 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8083
03-29 11:49:34 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8093
03-29 11:49:34 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8104
03-29 11:49:34 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8112
03-29 11:49:34 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8118
03-29 11:49:34 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8122
03-29 11:49:34 I new best model (accuracy1/test/cls_sgd_lr01_wupcos_wd0_default): 0.8054999709129333 --> 0.8057799935340881
03-29 11:49:34 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default model.th
03-29 11:49:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr01_wupcos_wd0_default.th
03-29 11:49:34 I new best model (accuracy1/test/cls_sgd_lr009_wupcos_wd0_default): 0.8063200116157532 --> 0.8069400191307068
03-29 11:49:34 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default model.th
03-29 11:49:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr009_wupcos_wd0_default.th
03-29 11:49:34 I new best model (accuracy1/test/cls_sgd_lr008_wupcos_wd0_default): 0.8069199919700623 --> 0.8075000047683716
03-29 11:49:34 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default model.th
03-29 11:49:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr008_wupcos_wd0_default.th
03-29 11:49:34 I new best model (accuracy1/test/cls_sgd_lr007_wupcos_wd0_default): 0.807640016078949 --> 0.8080400228500366
03-29 11:49:34 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default model.th
03-29 11:49:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr007_wupcos_wd0_default.th
03-29 11:49:34 I new best model (accuracy1/test/cls_sgd_lr003_wupcos_wd0_default): 0.8109999895095825 --> 0.8112000226974487
03-29 11:49:34 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default model.th
03-29 11:49:34 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr003_wupcos_wd0_default.th
03-29 11:49:34 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 11:57:27 I ------------------
03-29 11:57:27 I Epoch 48 (E48_U60048_S61489152)
03-29 11:57:27 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 11:57:27 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.67142192
03-29 11:57:27 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.67011556
03-29 11:57:27 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.66939256
03-29 11:57:27 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.66932597
03-29 11:57:27 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.67011862
03-29 11:57:27 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67202429
03-29 11:57:27 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.67564261
03-29 11:57:27 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68215185
03-29 11:57:27 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69431962
03-29 11:57:27 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72227842
03-29 11:57:27 I loss/online/total: 6.79679142
03-29 11:57:44 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.35
03-29 11:57:47 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8049
03-29 11:57:47 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8062
03-29 11:57:47 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8070
03-29 11:57:47 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8079
03-29 11:57:47 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8088
03-29 11:57:47 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8094
03-29 11:57:47 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8105
03-29 11:57:47 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8110
03-29 11:57:47 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8118
03-29 11:57:47 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8118
03-29 11:57:47 I new best model (accuracy1/test/cls_sgd_lr004_wupcos_wd0_default): 0.8104199767112732 --> 0.8105000257492065
03-29 11:57:47 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default model.th
03-29 11:57:47 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=best_model.accuracy1.test.cls_sgd_lr004_wupcos_wd0_default.th
03-29 11:57:47 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 12:05:40 I ------------------
03-29 12:05:40 I Epoch 49 (E49_U61299_S62770176)
03-29 12:05:40 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 12:05:40 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.66846933
03-29 12:05:40 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.66735184
03-29 12:05:40 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.66681982
03-29 12:05:40 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.66693014
03-29 12:05:40 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.66791140
03-29 12:05:40 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.66998269
03-29 12:05:40 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.67376751
03-29 12:05:40 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68037368
03-29 12:05:40 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69274714
03-29 12:05:40 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72102428
03-29 12:05:40 I loss/online/total: 6.77537783
03-29 12:05:57 I accuracy_logger_test_iter=0.00 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 12:06:00 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8058
03-29 12:06:00 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8060
03-29 12:06:00 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8069
03-29 12:06:00 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8076
03-29 12:06:00 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8084
03-29 12:06:00 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8094
03-29 12:06:00 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8104
03-29 12:06:00 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8110
03-29 12:06:00 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8116
03-29 12:06:00 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8122
03-29 12:06:00 I started dataloader iterator of AccuracyLogger(dataset_key=test)
03-29 12:13:53 I ------------------
03-29 12:13:53 I Epoch 50 (E50_U62550_S64051200)
03-29 12:13:53 I train_data=[0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00] train=[0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37, 0.37]
03-29 12:13:53 I loss/online/cls_sgd_lr01_wupcos_wd0_default: 0.66885896
03-29 12:13:53 I loss/online/cls_sgd_lr009_wupcos_wd0_default: 0.66779895
03-29 12:13:53 I loss/online/cls_sgd_lr008_wupcos_wd0_default: 0.66736375
03-29 12:13:53 I loss/online/cls_sgd_lr007_wupcos_wd0_default: 0.66751674
03-29 12:13:53 I loss/online/cls_sgd_lr006_wupcos_wd0_default: 0.66856948
03-29 12:13:53 I loss/online/cls_sgd_lr005_wupcos_wd0_default: 0.67076981
03-29 12:13:53 I loss/online/cls_sgd_lr004_wupcos_wd0_default: 0.67459867
03-29 12:13:53 I loss/online/cls_sgd_lr003_wupcos_wd0_default: 0.68133835
03-29 12:13:53 I loss/online/cls_sgd_lr002_wupcos_wd0_default: 0.69384537
03-29 12:13:53 I loss/online/cls_sgd_lr001_wupcos_wd0_default: 0.72226507
03-29 12:13:53 I loss/online/total: 6.78292515
03-29 12:14:10 I accuracy_logger_test_iter=0.01 accuracy_logger_test_data=0.00 accuracy_logger_test_forward=0.36
03-29 12:14:13 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default: 0.8058
03-29 12:14:13 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default: 0.8066
03-29 12:14:13 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default: 0.8075
03-29 12:14:13 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default: 0.8076
03-29 12:14:13 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default: 0.8084
03-29 12:14:13 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default: 0.8092
03-29 12:14:13 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default: 0.8101
03-29 12:14:13 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default: 0.8109
03-29 12:14:13 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default: 0.8114
03-29 12:14:13 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default: 0.8117
03-29 12:14:13 I ------------------
03-29 12:14:13 I AFTER TRAINING
03-29 12:14:13 I ------------------
03-29 12:14:13 I accuracy_logger dataset_key=test
03-29 12:14:13 I total_iter:   [10.02, 10.37, 10.29, 10.18, 10.57, 10.22, 10.27, 10.30]
03-29 12:14:13 I total_data_time:    [0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
03-29 12:14:13 I total_forward_time: [17.75, 17.75, 17.80, 17.80, 17.79, 17.79, 17.71, 17.73]
03-29 12:14:16 I saved backbone_head.backbone to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.backbone cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr01_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr01_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr009_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr009_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr008_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr008_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr007_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr007_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr006_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr006_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr005_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr005_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr004_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr004_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr003_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr003_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr002_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr002_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved backbone_head.head.cls_sgd_lr001_wupcos_wd0_default to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/backbone_head.head.cls_sgd_lr001_wupcos_wd0_default cp=last model.th
03-29 12:14:16 I saved trainer state_dict to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/checkpoints/trainer cp=last.th
03-29 12:14:17 I writing 1301 log entries to /home/it4i-johleh/scratch/save_mlp/probe/1h2ha4n0/primitive/entries.yaml
03-29 12:14:19 I ------------------
03-29 12:14:19 I summarize logvalues
03-29 12:14:24 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/max: 0.8124600052833557
03-29 12:14:24 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/last10: 0.8120439946651459
03-29 12:14:24 I accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/last50: 0.8063943994045257
03-29 12:14:24 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default/max: 0.8120800256729126
03-29 12:14:24 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default/last10: 0.8117259979248047
03-29 12:14:24 I accuracy1/test/cls_sgd_lr002_wupcos_wd0_default/last50: 0.8056931972503663
03-29 12:14:24 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default/max: 0.8112000226974487
03-29 12:14:24 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default/last10: 0.810809999704361
03-29 12:14:24 I accuracy1/test/cls_sgd_lr003_wupcos_wd0_default/last50: 0.8037211990356445
03-29 12:14:24 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default/max: 0.8105000257492065
03-29 12:14:24 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default/last10: 0.8099680006504059
03-29 12:14:24 I accuracy1/test/cls_sgd_lr004_wupcos_wd0_default/last50: 0.8014751982688904
03-29 12:14:24 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default/max: 0.8095600008964539
03-29 12:14:24 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default/last10: 0.8089540004730225
03-29 12:14:24 I accuracy1/test/cls_sgd_lr005_wupcos_wd0_default/last50: 0.7990908026695251
03-29 12:14:24 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default/max: 0.8089399933815002
03-29 12:14:24 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default/last10: 0.8079799950122833
03-29 12:14:24 I accuracy1/test/cls_sgd_lr006_wupcos_wd0_default/last50: 0.7968024015426636
03-29 12:14:24 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default/max: 0.8080400228500366
03-29 12:14:24 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default/last10: 0.8070219993591309
03-29 12:14:24 I accuracy1/test/cls_sgd_lr007_wupcos_wd0_default/last50: 0.794372798204422
03-29 12:14:24 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default/max: 0.8075000047683716
03-29 12:14:24 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default/last10: 0.806470000743866
03-29 12:14:24 I accuracy1/test/cls_sgd_lr008_wupcos_wd0_default/last50: 0.7922123992443084
03-29 12:14:24 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default/max: 0.8069400191307068
03-29 12:14:24 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default/last10: 0.8056400060653687
03-29 12:14:24 I accuracy1/test/cls_sgd_lr009_wupcos_wd0_default/last50: 0.7901212036609649
03-29 12:14:24 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default/max: 0.8057799935340881
03-29 12:14:24 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default/last10: 0.8047340035438537
03-29 12:14:24 I accuracy1/test/cls_sgd_lr01_wupcos_wd0_default/last50: 0.7880527997016906
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/E1/min: 0.7210242812969179
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/E1/last10: 0.7240385177659152
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/E1/last50: 0.8384923385651553
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/U50/min: 0.705632881373167
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/U50/last10: 0.7187545982599258
03-29 12:14:24 I loss/online/cls_sgd_lr001_wupcos_wd0_default/U50/last50: 0.7216523538455368
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/E1/min: 0.6927471385090995
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/E1/last10: 0.6969042433123531
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/E1/last50: 0.8069703253686165
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/U50/min: 0.6774944955855609
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/U50/last10: 0.6905818038061262
03-29 12:14:24 I loss/online/cls_sgd_lr002_wupcos_wd0_default/U50/last50: 0.6932995839774607
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/E1/min: 0.6803736750253861
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/E1/last10: 0.685629426464617
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/E1/last50: 0.8018813114072516
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/U50/min: 0.6652255979925393
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/U50/last10: 0.6781972365155815
03-29 12:14:24 I loss/online/cls_sgd_lr003_wupcos_wd0_default/U50/last50: 0.680858187788725
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/E1/min: 0.6737675068827033
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/E1/last10: 0.6800680925410024
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/E1/last50: 0.8074084140658141
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/U50/min: 0.6586728429794311
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/U50/last10: 0.6714447835572065
03-29 12:14:24 I loss/online/cls_sgd_lr004_wupcos_wd0_default/U50/last50: 0.6741848210193218
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/E1/min: 0.6699826892146723
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/E1/last10: 0.6773764584789709
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/E1/last50: 0.819048081202705
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/U50/min: 0.6549848610907792
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/U50/last10: 0.6676627087630331
03-29 12:14:24 I loss/online/cls_sgd_lr005_wupcos_wd0_default/U50/last50: 0.6703775431789458
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/E1/min: 0.6679114023093982
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/E1/last10: 0.6763724386827539
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/E1/last50: 0.8348818935788305
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/U50/min: 0.6530055221170187
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/U50/last10: 0.6654560855925085
03-29 12:14:24 I loss/online/cls_sgd_lr006_wupcos_wd0_default/U50/last50: 0.668241318899393
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/E1/min: 0.6669301410629261
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/E1/last10: 0.6765203304813622
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/E1/last50: 0.85422941087798
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/U50/min: 0.6522332403063774
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/U50/last10: 0.6644057921357452
03-29 12:14:24 I loss/online/cls_sgd_lr007_wupcos_wd0_default/U50/last50: 0.667224978467822
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/E1/min: 0.666819822507725
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/E1/last10: 0.6775331286251915
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/E1/last50: 0.8765894503919163
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/U50/min: 0.6520215310901404
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/U50/last10: 0.6642677144482731
03-29 12:14:24 I loss/online/cls_sgd_lr008_wupcos_wd0_default/U50/last50: 0.667093331734836
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/E1/min: 0.6673518381208825
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/E1/last10: 0.679231226951819
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/E1/last50: 0.9014960998384584
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/U50/min: 0.6525853639841079
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/U50/last10: 0.6646880828365683
03-29 12:14:24 I loss/online/cls_sgd_lr009_wupcos_wd0_default/U50/last50: 0.6675776792272927
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/E1/min: 0.6684693325605753
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/E1/last10: 0.6815316840014656
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/E1/last50: 0.9289325719682886
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/U50/min: 0.653580995351076
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/U50/last10: 0.6657616366483271
03-29 12:14:24 I loss/online/cls_sgd_lr01_wupcos_wd0_default/U50/last50: 0.6686667696855964
03-29 12:14:24 I loss/online/total/E1/min: 6.775377826820269
03-29 12:14:24 I loss/online/total/E1/last10: 6.855205547973978
03-29 12:14:24 I loss/online/total/E1/last50: 8.469929897555534
03-29 12:14:24 I loss/online/total/U50/min: 6.626975488066672
03-29 12:14:24 I loss/online/total/U50/last10: 6.751220451533794
03-29 12:14:24 I loss/online/total/U50/last50: 6.779176569128037
03-29 12:14:24 I pushing summarized logvalues to wandb
03-29 12:14:24 I ------------------
03-29 12:14:24 I pattern=accuracy1/test*/last best_key='accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/last' best_value=0.811680018901825
03-29 12:14:24 I pattern=accuracy1/test*/max best_key='accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/max' best_value=0.8124600052833557
03-29 12:14:24 I pattern=accuracy1/test/cls_*/last best_key='accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/last' best_value=0.811680018901825
03-29 12:14:24 I pattern=accuracy1/test/cls_*/max best_key='accuracy1/test/cls_sgd_lr001_wupcos_wd0_default/max' best_value=0.8124600052833557
03-29 12:14:25 I full profiling times:
 24708.41 train
     0.00 train.EtaLogger.before_training
     0.04 train.DatasetStatsLogger.before_training
     0.00 train.ParamCountLogger.before_training
     0.15 train.AccuracyLogger.before_training
     0.00 train.CheckpointLogger.before_training
     0.00 train.BestModelLogger.before_training
    36.84 train.iterator
    24.00 train.data_loading
 23202.42 train.update
     2.13 train.OnlineLossLogger.track_after_accumulation_step
    26.06 train.EtaLogger.track_after_update_step
     0.30 train.TrainTimeLogger.track_after_update_step
     0.13 train.LrLogger.after_update
     0.04 train.FreezerLogger.after_update
     3.78 train.OnlineLossLogger.after_update
     0.00 train.EtaLogger.after_epoch
     0.03 train.ProgressLogger.after_epoch
     0.12 train.TrainTimeLogger.after_epoch
     0.30 train.OnlineLossLogger.after_epoch
  1003.92 train.AccuracyLogger.after_epoch
     2.11 train.BestModelLogger.after_epoch
     0.01 train.AccuracyLogger.after_training
     3.17 train.CheckpointLogger.after_training
     0.00 train.BestModelLogger.after_training
03-29 12:14:25 I ------------------
03-29 12:14:25 I CLEANUP
03-29 12:14:25 I ------------------
03-29 12:14:25 I encountered 0 warnings
03-29 12:14:25 I encountered 0 errors
03-29 12:14:32 I ------------------
03-29 12:14:32 I 481 tensors remaining in memory (cpu+gpu)
03-29 12:14:32 I 1 tensors remaining in memory (cpu)
03-29 12:14:32 I 480 tensors remaining in memory (gpu)
