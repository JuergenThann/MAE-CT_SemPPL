vars:
#  model_name: backbone_head.backbone
#  continue_from_stage_id: 99e8ujyo
#  continue_from_stage_name: cifar100_stage2_mae_finetuning
#  base_name: CIFAR-100 MAE + Fine-Tuning 10% (MAE 1op crop0.8 nodroppath lr+ lwlrd+ 150ep)

  model_name: semivit.target_encoder
  continue_from_stage_id: w1hfg64f
  continue_from_stage_name: cifar100_stage3_mae_finetuning_fixmatch
  base_name: CIFAR-100 MAE + Fine-Tuning 10% (MAE 1op crop0.8 nodroppath lr+ lwlrd+ 150ep) + FixMatch 10% (SemiViT crop=0.8 1op -ProbPseudo lr0.005 lwlrd0.75 tf0.9999 250ep)

#  model_name: backbone_head.backbone
#  continue_from_stage_id: 1q2prq7m
#  continue_from_stage_name: cifar100_stage3_mae_semppl_finetuning
#  base_name: CIFAR-100 MAE + SemPPL 10% (aug=SimpSemPPL smallcrop=0.08-1) + Fine-Tuning 10% (MAE 1op crop0.8 nodroppath lwlrd+ 150ep)

#  model_name: mae_contheads_vit.target_encoder
#  continue_from_stage_id: ptioxtz7
#  continue_from_stage_name: cifar100_stage2_mae_semppl+fixmatch
#  base_name: CIFAR-100 MAE + SemPPL 10% (aug=SimpSemPPL smallcrop=0.08-1) & FixMatch 10% (SemiViT crop=0.8 1op -ProbPseudo lr0.005 lwlrd0.75 tf0.9999) 1:0.25

name: ${vars.base_name} - UMAP

stage_name: umap
ignore_stage_name: true
datasets:
  train:
    kind: torchvision_dataset_wrapper
    dataset_identifier: cifar100
    num_classes: 100
    torchvision_args:
      kind: CIFAR100
      train: true
      download: false
    dataset_wrappers:
      - kind: subset_wrapper
        end_index: 128
    sample_wrappers:
      - kind: x_transform_wrapper
        transform:
          - kind: kd_cifar100_norm
  test_small:
    kind: torchvision_dataset_wrapper
    dataset_identifier: cifar100
    num_classes: 100
    torchvision_args:
      kind: CIFAR100
      train: false
      download: false
    dataset_wrappers:
      - kind: class_filter_wrapper
        valid_classes:
          - 0
          - 1
          - 2
          - 3
          - 4
          - 5
          - 6
          - 7
          - 8
          - 9
    x_transform:
      - kind: kd_cifar100_norm
model:
  kind: backbone_head
  backbone:
    kind: vit.vit_mae
    patch_size: 4
    embedding_dim: 192
    depth: 12
    attention_heads: 3
    is_frozen: true
    # drop_path_rate: ${vars.drop_path}
    initializer:
      checkpoint: last
      kind: previous_run_initializer
      model_name: ${vars.model_name}
      stage_id: ${vars.continue_from_stage_id}
      stage_name: ${vars.continue_from_stage_name}
  head:
    kind: heads.linear_head
    nonaffine_batchnorm: true
    pooling:
      kind: class_token
      # kind: mean_patch
    optim:
      kind: adamw
      lr: 0.001
      weight_decay: 0.05
      betas:
        - 0.9
        - 0.999
      schedule:
        - exclude_last: true
          kind: cosine_decreasing
    initializer:
      kind: trunc_normal_initializer
      std: 0.01
trainer:
  kind: classification_trainer
  max_epochs: 1
  effective_batch_size: 128
  precision: bfloat16
  log_every_n_epochs: 1
  loggers:
    - kind: feature_umap_logger
      dataset_key: test_small
      every_n_epochs: 1
      n_components: 2
      n_neighbors: 100
      min_dist: 0.2
      metric: 'euclidean'
      classes_to_render:
        - 0
        - 1
        - 2
        - 3
        - 4
        - 5
        - 6
        - 7
        - 8
        - 9
#      class_names_to_render:
#        - streetcar
#        - motorcycle
##        - sunflower
##        - bee
##        - road
##        - motorcycle
##        - bridge
##        - sea
##        - shark
##        - dolphin
#      num_samples_to_render: 10
      extractors:
        - kind: generic_extractor
          model_property_path: head.pooling
