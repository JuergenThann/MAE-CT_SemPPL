ignore_specific_stage_names: true
stages:
  execution1:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - end_percent: ${vars.label_percentage}
          kind: classwise_subset_wrapper
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: x_transform_wrapper
          transform:
          - kind: random_horizontal_flip
          - interpolation: bicubic
            kind: kd_random_resized_crop
            scale:
            - ${vars.crop}
            - 1.0
            size: 32
          - apply_op_p: ${vars.randaug_apply_op_p}
            fill_color:
            - 125
            - 123
            - 114
            interpolation: bicubic
            kind: kd_rand_augment
            magnitude: ${vars.randaug_magnitude}
            magnitude_std: ${vars.randaug_magnitude_std}
            num_ops: ${vars.randaug_num_ops}
          - kind: kd_cifar100_norm
        - kind: label_smoothing_wrapper
          smoothing: ${vars.label_smoothing}
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      backbone:
        attention_heads: 3
        depth: 12
        drop_path_rate: ${vars.drop_path}
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: mae_contheads_vit.encoder
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.vit_mae
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      head:
        initializer:
          kind: trunc_normal_initializer
          std: 0.01
        kind: heads.linear_head
        nonaffine_batchnorm: true
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        pooling:
          kind: class_token
      kind: backbone_head
    name: CIFAR-100 MAE + Fine-Tuning ${eval:int(${vars.label_percentage} * 100)}%
      (MAE ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if ${vars.drop_path}
      == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is None else ''}mixup
      lr${vars.lr} lwlrd${vars.layerwise_lr_decay} ${vars.max_epochs}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage2_mae_finetuning
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: classification_trainer
      log_every_n_epochs: 1
      loggers:
      - dataset_key: train
        every_n_epochs: 1
        kind: accuracy_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
      - dataset_key: train
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/main
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      max_epochs: ${vars.max_epochs}
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      continue_from_stage_id: bymoyvsh
      continue_from_stage_name: cifar100_stage1_mae
      crop: 0.4
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.002
      max_epochs: 200
      mixup: 0.8
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      warmup_epochs: 20
      weight_decay: 0.3
