stages:
  execution1:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: xvs5hvuw
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 50
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution10:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: xvs5hvuw
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 250
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution11:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: oswus3mh
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 250
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution12:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 030h7yt2
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 350
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution13:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: bsptnh8g
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 350
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution14:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: ziqzgjyn
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 450
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution15:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: d8u3yb81
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 450
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution16:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: lzpfd8wy
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 550
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution17:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 488w0wh4
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 50
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution18:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: l6snjer1
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 50
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution19:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: xvs5hvuw
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 75
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution2:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: oswus3mh
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 50
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution20:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: oswus3mh
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 75
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution21:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 030h7yt2
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 100
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution22:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: bsptnh8g
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 100
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution23:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: ziqzgjyn
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 150
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution24:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: d8u3yb81
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 150
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution25:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: lzpfd8wy
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 200
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution26:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 488w0wh4
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 250
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution27:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: l6snjer1
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 250
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution28:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: xvs5hvuw
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 350
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution29:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: oswus3mh
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 350
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution3:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 030h7yt2
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 75
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution30:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 030h7yt2
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 450
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution31:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: bsptnh8g
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 450
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution32:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: ziqzgjyn
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 550
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution33:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 50
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: d8u3yb81
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 550
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution4:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: bsptnh8g
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 75
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution5:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: ziqzgjyn
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 100
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution6:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: d8u3yb81
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 100
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution7:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: lzpfd8wy
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 150
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution8:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: 488w0wh4
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 200
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
  execution9:
    datasets:
      test:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      test_small:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: false
        x_transform:
        - kind: kd_cifar100_norm
      train:
        batch_wrappers:
        - cutmix_alpha: ${vars.cutmix}
          cutmix_p: 0.5
          kind: prob_pseudo_mix_batch_wrapper
          label_smoothing: ${vars.label_smoothing}
          mixup_alpha: ${vars.mixup}
          mixup_p: 0.5
          model_name: semivit
          n_classes: 100
          prediction_head_name: fixmatch
          shuffle_mode: flip
          supervised_mixup_mode: ${vars.supervised_mixup_mode}
          unsupervised_mixup_mode: ${vars.unsupervised_mixup_mode}
          weak_augmentation_index: 0
        collators: ${vars.collators}
        dataset_identifier: cifar100
        dataset_wrappers:
        - kind: semisupervised_wrapper
          labeled_percentage: ${eval:${vars.label_percentage}*100}
        - include_labeled_in_unlabeled: true
          kind: semisupervised_oversampling_wrapper
          unlabeled_to_labeled_ratio: ${vars.unlabeled_to_labeled_ratio}
        kind: torchvision_dataset_wrapper
        num_classes: 100
        sample_wrappers:
        - kind: multi_view_wrapper
          transforms:
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - brightness: ${vars.color_jitter}
              contrast: ${vars.color_jitter}
              kind: kd_color_jitter
              saturation: ${vars.color_jitter}
            - kind: kd_cifar100_norm
          - - interpolation: bicubic
              kind: kd_random_resized_crop
              scale:
              - ${vars.crop}
              - 1.0
              size: 32
            - kind: kd_random_horizontal_flip
            - apply_op_p: ${vars.randaug_apply_op_p}
              fill_color:
              - 125
              - 123
              - 114
              interpolation: bicubic
              kind: kd_rand_augment
              magnitude: ${vars.randaug_magnitude}
              magnitude_std: ${vars.randaug_magnitude_std}
              num_ops: ${vars.randaug_num_ops}
            - kind: kd_cifar100_norm
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
      train_unaugmented:
        dataset_identifier: cifar100
        kind: torchvision_dataset_wrapper
        num_classes: 100
        torchvision_args:
          download: false
          kind: CIFAR100
          train: true
        x_transform:
        - kind: kd_cifar100_norm
    ignore_stage_name: true
    model:
      contrastive_heads:
        fixmatch:
          initializer:
            checkpoint: last
            kind: previous_run_initializer
            model_name: backbone_head.head
            stage_id: ${vars.continue_from_stage_id}
            stage_name: ${vars.continue_from_stage_name}
          kind: heads.fixmatch_head
          nonaffine_batchnorm: true
          optim:
            betas:
            - 0.9
            - ${vars.beta2}
            kind: adamw
            lr: ${vars.lr}
            lr_scaler:
              divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
                / (${vars.unlabeled_to_labeled_ratio}+1))}
              kind: linear_lr_scaler
            schedule:
            - end_checkpoint:
                epoch: ${vars.warmup_epochs}
              exclude_first: true
              exclude_last: true
              kind: linear_increasing
            - end_checkpoint:
                epoch: ${vars.max_epochs_schedule}
              exclude_last: true
              kind: cosine_decreasing
            weight_decay: ${vars.weight_decay}
          output_shape: 100
          pooling:
            kind: class_token
          strong_augmentation_for_labeled: ${vars.strong_augmentation_for_labeled}
          target_factor: ${vars.target_factor}
          teacher_pseudo_labeling: ${vars.teacher_pseudo_labeling}
          threshold: ${vars.threshold}
          unsupervised_loss_weight: ${vars.unsupervised_loss_weight}
      encoder:
        attention_heads: 3
        depth: 12
        embedding_dim: 192
        initializer:
          checkpoint: last
          kind: previous_run_initializer
          model_name: backbone_head.backbone
          stage_id: ${vars.continue_from_stage_id}
          stage_name: ${vars.continue_from_stage_name}
        kind: vit.masked_encoder
        optim:
          betas:
          - 0.9
          - ${vars.beta2}
          kind: adamw
          lr: ${vars.lr}
          lr_scaler:
            divisor: ${eval:${vars.batch_size} * ${vars.n_views} * 256 / (${vars.batch_size}
              / (${vars.unlabeled_to_labeled_ratio}+1))}
            kind: linear_lr_scaler
          param_group_modifiers:
          - decay: ${vars.layerwise_lr_decay}
            kind: layerwise_lr_decay_modifier
          schedule:
          - end_checkpoint:
              epoch: ${vars.warmup_epochs}
            exclude_first: true
            exclude_last: true
            kind: linear_increasing
          - end_checkpoint:
              epoch: ${vars.max_epochs_schedule}
            exclude_last: true
            kind: cosine_decreasing
          weight_decay: ${vars.weight_decay}
        patch_size: 4
      kind: mae_contheads_vit
      name: semivit
      target_factor: ${vars.target_factor}
    name: CIFAR-100 MAE + Fine-Tuning 1% (MAE 1op crop0.4 nodroppath nomixup lr0.002
      lwlrd0.75 ${vars.prev_max_epochs}ep BS24) + FixMatch ${eval:int(${vars.label_percentage}
      * 100)}% (SemiViT ${vars.randaug_num_ops}op crop${vars.crop} ${eval:'no' if
      ${vars.drop_path} == 0.0 else ''}droppath ${eval:'no' if ${vars.collators} is
      None else ''}mixup lr${vars.lr} lwlrd${vars.layerwise_lr_decay} tf${vars.target_factor}
      ${vars.max_epochs}${eval:'/${vars.max_epochs_schedule}' if ${vars.max_epochs}
      != ${vars.max_epochs_schedule} else ''}ep BS${vars.batch_size})
    num_workers: 1
    stage_name: cifar100_stage3_mae_finetuning_fixmatch
    summary_summarizers:
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/train_unaugmented*/max
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/last
    - kind: best_metric_summary_summarizer
      pattern: accuracy1/test*/max
    - kind: best_metric_summary_summarizer
      pattern: knn_accuracy/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    - kind: best_metric_summary_summarizer
      pattern: nn_purity/knn*/GenericExtractor-batchnorm/train_unaugmented-test/max
    trainer:
      effective_batch_size: ${vars.batch_size}
      kind: mae_contheads_vit_trainer
      log_every_n_epochs: 1
      loggers:
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: supervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss
      - category: loss
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: unsupervised_loss_mean_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: samples_above_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_unlabeled_over_threshold
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: classification_confidence_labeled
      - category: confidence
        every_n_epochs: 1
        invert_key: false
        kind: group_update_output_logger
        pattern: pseudo_label_accuracy
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: test
        every_n_epochs: 1
        kind: loss_logger
      - dataset_key: train_unaugmented
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: train_unaugmented
          views:
          - 0
      - dataset_key: test
        every_n_epochs: 1
        kind: accuracy_logger
        predict_kwargs:
          dataset_key: test
          views:
          - 0
      - every_n_epochs: 50
        kind: checkpoint_logger
        save_latest_optim: false
        save_optim: false
      - every_n_epochs: 1
        kind: best_model_logger
        metric_key: accuracy1/test/fixmatch
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/train_unaugmented*
      - every_n_epochs: 1
        kind: best_metric_logger
        pattern: accuracy1/test*
      - every_n_epochs: 1
        kind: best_metric_logger
        log_absolute_best: true
        pattern: accuracy1/test*
      - dataset_key: test_small
        every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: feature_umap_logger
        metric: euclidean
        min_dist: 0.2
        n_components: 2
        n_neighbors: 100
      - every_n_epochs: ${vars.max_epochs}
        extractors:
        - kind: generic_extractor
          model_property_path: contrastive_heads.fixmatch.target_head.pooling
        kind: knn_metrics_logger
        knns:
        - 1
        - 2
        - 3
        - 5
        - 8
        - 13
        - 21
        test_dataset_key: test
        train_dataset_key: train_unaugmented
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn01/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn02/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn03/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn05/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn08/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn13/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn21/
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: knn_accuracy/knn*
      - every_n_epochs: ${vars.max_epochs}
        kind: best_metric_logger
        pattern: nn_purity/knn*
      mask_generator:
        kind: random_mask_generator
        mask_ratio: 0.0
      max_epochs: ${vars.max_epochs}
      normalize_pixels: true
      precision: bfloat16
    vars:
      batch_size: 24
      beta2: 0.999
      collators: null
      color_jitter: 0.4
      continue_from_stage_id: l6snjer1
      continue_from_stage_name: cifar100_stage2_mae_finetuning
      crop: 0.8
      cutmix: 1.0
      drop_path: 0.0
      label_percentage: 0.01
      label_smoothing: 0.1
      layerwise_lr_decay: 0.75
      lr: 0.005
      max_epochs: 50
      max_epochs_schedule: 250
      mixup: 0.8
      n_views: 2
      prev_max_epochs: 200
      randaug_apply_op_p: 1
      randaug_magnitude: 9
      randaug_magnitude_std: 0.5
      randaug_num_ops: 1
      strong_augmentation_for_labeled: true
      supervised_mixup_mode: null
      target_factor: 0.9999
      teacher_pseudo_labeling: true
      threshold: 0.6
      unlabeled_to_labeled_ratio: 5
      unsupervised_loss_weight: 5
      unsupervised_mixup_mode: null
      warmup_epochs: 5
      weight_decay: 0.05
